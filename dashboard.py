#!/usr/bin/env python3
"""
ãƒ•ãƒ«æ©Ÿèƒ½ Streamlit çµŒæ¸ˆãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰ï¼ˆæ¥ç¶šå®‰å®šåŒ–ç‰ˆï¼‰
"""

import streamlit as st
import pandas as pd
import plotly.graph_objs as go
import plotly.express as px
from datetime import datetime, timedelta
import time
import os
import requests
import json
import investpy

# ãƒšãƒ¼ã‚¸è¨­å®š
st.set_page_config(
    page_title="ğŸ“Š Economic Dashboard",
    page_icon="ğŸ“Š",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ãƒ€ãƒ¼ã‚¯ãƒ†ãƒ¼ãƒç”¨CSS
st.markdown("""
<style>
    .stApp {
        background-color: #1e1e1e;
        color: #ffffff;
    }
    .stSelectbox > div > div {
        background-color: #3d3d3d;
        color: #ffffff;
    }
    .stMetric {
        background-color: #2d2d2d;
        padding: 1rem;
        border-radius: 0.5rem;
    }
    .main-header {
        text-align: center;
        color: #4CAF50;
        font-size: 3rem;
        margin-bottom: 2rem;
    }
    .status-indicator {
        position: fixed;
        top: 10px;
        right: 10px;
        background-color: #4CAF50;
        color: white;
        padding: 5px 10px;
        border-radius: 15px;
        font-size: 12px;
        z-index: 1000;
    }
</style>
""", unsafe_allow_html=True)

# æ¥ç¶šçŠ¶æ…‹è¡¨ç¤º
st.markdown(f'<div class="status-indicator">ğŸŸ¢ Live â€¢ {time.strftime("%H:%M:%S")}</div>', unsafe_allow_html=True)


def fetch_fallback_data():
    """ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨ã®ç°¡å˜ãªãƒ‡ãƒ¼ã‚¿å–å¾—"""
    try:
        # æœ€å°é™ã®APIã‹ã‚‰ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚’è©¦è¡Œ
        url = "https://nfs.faireconomy.media/ff_calendar_thisweek.json"
        headers = {'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'}
        
        response = requests.get(url, headers=headers, timeout=10)
        if response.status_code == 200:
            data = response.json()
            if isinstance(data, list) and len(data) > 0:
                df = pd.DataFrame(data)
                st.info(f"ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯APIã‹ã‚‰ {len(df)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—")
                return df
    except Exception as e:
        st.warning(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚‚å¤±æ•—: {e}")
    
    return None

def update_data_file():
    """æœˆã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ›´æ–°"""
    try:
        # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªä½œæˆ
        os.makedirs("./data", exist_ok=True)
        
        # éå»5å¹´åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        today = datetime.now()
        months_to_fetch = []
        
        # éå»5å¹´åˆ† + å°†æ¥1ãƒ¶æœˆåˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆ61ãƒ¶æœˆï¼‰
        for i in range(-1, 60):  # -1ã§1ãƒ¶æœˆå…ˆã‚‚å«ã‚€
            target_date = today - timedelta(days=30*i)
            months_to_fetch.append(target_date)
        
        total_new_data = 0
        
        for target_date in months_to_fetch:
            year_month = target_date.strftime('%Y-%m')
            monthly_file = f"./data/economic_data_{year_month}.csv"
            
            # æœˆã”ã¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ãªã„ã‹ã€å¤ã„å ´åˆã¯æ›´æ–°
            update_needed = False
            
            if os.path.exists(monthly_file):
                file_time = datetime.fromtimestamp(os.path.getmtime(monthly_file))
                # 6æ™‚é–“ä»¥ä¸Šå¤ã„å ´åˆã¯æ›´æ–°
                if datetime.now() - file_time > timedelta(hours=6):
                    update_needed = True
                    # ãƒ‡ãƒ¼ã‚¿æ›´æ–°ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‰Šé™¤
            else:
                update_needed = True
                # æ–°è¦ãƒ‡ãƒ¼ã‚¿å–å¾—ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã‚’å‰Šé™¤
            
            if update_needed:
                with st.spinner(f"ğŸ”„ {year_month} ã®çµŒæ¸ˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­..."):
                    # æœˆã®é–‹å§‹æ—¥ã¨çµ‚äº†æ—¥ã‚’è¨ˆç®—
                    first_day = target_date.replace(day=1)
                    if target_date.month == 12:
                        last_day = target_date.replace(year=target_date.year+1, month=1, day=1) - timedelta(days=1)
                    else:
                        last_day = target_date.replace(month=target_date.month+1, day=1) - timedelta(days=1)
                    
                    from_date = first_day.strftime('%d/%m/%Y')
                    # å°†æ¥ã®æ—¥ä»˜ã‚‚å«ã‚ã¦å–å¾—ï¼ˆinvestpyã§å°†æ¥ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼å–å¾—å¯èƒ½ï¼‰
                    to_date = last_day.strftime('%d/%m/%Y')
                    
                    # æœˆã”ã¨ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                    monthly_data = fetch_monthly_economic_data(from_date, to_date, year_month)
                    
                    if monthly_data is not None and not monthly_data.empty:
                        # æœˆã”ã¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                        monthly_data.to_csv(monthly_file, index=False)
                        total_new_data += len(monthly_data)
                        # æˆåŠŸãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯å‰Šé™¤ï¼ˆæœ€å¾Œã«ã¾ã¨ã‚ã¦è¡¨ç¤ºï¼‰
                    else:
                        st.warning(f"âš ï¸ {year_month}: ãƒ‡ãƒ¼ã‚¿å–å¾—ã«å¤±æ•—")
        
        # çµ±åˆãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ
        create_combined_data_file()
        
        if total_new_data > 0:
            st.success(f"ğŸ‰ åˆè¨ˆ {total_new_data}ä»¶ã®æ–°ã—ã„ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ã—ã¾ã—ãŸ")
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢
            load_data.clear()
        else:
            # ã€Œæœ€æ–°ã§ã™ã€ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯éè¡¨ç¤ºã«
            pass
            
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿æ›´æ–°ã‚¨ãƒ©ãƒ¼: {e}")
        # ã‚¨ãƒ©ãƒ¼æ™‚ã®æƒ…å ±ã¯å‰Šé™¤

def fetch_monthly_economic_data(from_date, to_date, year_month):
    """æŒ‡å®šæœŸé–“ã®çµŒæ¸ˆãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ï¼ˆinvestpyã‚’ä½¿ç”¨ï¼‰"""
    try:
        # å–å¾—æœŸé–“ã®è¡¨ç¤ºã‚’å‰Šé™¤
        
        # investpyã§çµŒæ¸ˆã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
        economic_data = investpy.economic_calendar(
            time_zone=None,
            countries=['united states', 'euro zone', 'united kingdom', 'japan', 'australia'],
            from_date=from_date,
            to_date=to_date
        )
        
        if not economic_data.empty:
            # ãƒ‡ãƒãƒƒã‚°: å…ƒã®åˆ—åã‚’ç¢ºèª
            # ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã¯éè¡¨ç¤º
            
            # é€šè²¨ã‚³ãƒ¼ãƒ‰ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆzoneåˆ—ã‹ã‚‰ï¼‰
            currency_mapping = {
                'united states': 'USD',
                'euro zone': 'EUR', 
                'united kingdom': 'GBP',
                'japan': 'JPY',
                'australia': 'AUD'
            }
            
            # zoneåˆ—ã‚’currencyã«å¤‰æ›
            if 'zone' in economic_data.columns:
                economic_data['currency'] = economic_data['zone'].map(currency_mapping).fillna(economic_data['zone'])
            else:
                economic_data['currency'] = 'Unknown'
            
            # å¿…è¦ãªåˆ—ã®ã¿é¸æŠã—ã¦æ–°ã—ã„DataFrameã‚’ä½œæˆ
            result_data = {
                'date': economic_data.get('date', ''),
                'time': economic_data.get('time', ''),
                'currency': economic_data.get('currency', 'Unknown'),
                'importance': economic_data.get('importance', ''),
                'event': economic_data.get('event', ''),
                'actual': economic_data.get('actual', ''),
                'forecast': economic_data.get('forecast', ''),
                'previous': economic_data.get('previous', '')
            }
            
            result_df = pd.DataFrame(result_data)
            
            # IDã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
            result_df.insert(0, 'id', range(len(result_df)))
            
            return result_df
        else:
            return None
            
    except Exception as e:
        st.error(f"investpy {year_month} ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return fetch_fallback_data()

def create_combined_data_file():
    """æœˆã”ã¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’çµ±åˆã—ã¦å˜ä¸€ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
    try:
        data_files = []
        data_dir = "./data"
        
        # æœˆã”ã¨ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢
        for filename in os.listdir(data_dir):
            if filename.startswith("economic_data_") and filename.endswith(".csv"):
                data_files.append(os.path.join(data_dir, filename))
        
        if data_files:
            combined_data = []
            total_files = len(data_files)
            
            # ãƒ•ã‚¡ã‚¤ãƒ«ã‚’é™ã‹ã«èª­ã¿è¾¼ã¿
            for file_path in sorted(data_files):
                try:
                    monthly_data = pd.read_csv(file_path)
                    combined_data.append(monthly_data)
                except Exception as e:
                    st.warning(f"âš ï¸ ãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {file_path} - {e}")
            
            if combined_data:
                # å…¨ãƒ‡ãƒ¼ã‚¿ã‚’çµåˆ
                all_data = pd.concat(combined_data, ignore_index=True)
                
                # é‡è¤‡ã‚’é™¤å»
                all_data = all_data.drop_duplicates()
                
                # çµ±åˆãƒ•ã‚¡ã‚¤ãƒ«ã«ä¿å­˜
                combined_file = "./data/economic_data.csv"
                all_data.to_csv(combined_file, index=False)
                
                st.success(f"ğŸ“Š ãƒ‡ãƒ¼ã‚¿çµ±åˆå®Œäº†: {total_files}ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰{len(all_data)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ")
                
            else:
                st.warning("ğŸ“ çµ±åˆå¯èƒ½ãªãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        else:
            # ãƒ•ã‚¡ã‚¤ãƒ«æœªç™ºè¦‹ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ã¯å‰Šé™¤
            pass
    except Exception as e:
        st.error(f"ãƒ•ã‚¡ã‚¤ãƒ«çµ±åˆã‚¨ãƒ©ãƒ¼: {e}")

@st.cache_data(ttl=1800, show_spinner=False)  # 30åˆ†ã‚­ãƒ£ãƒƒã‚·ãƒ¥
def load_data():
    """ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã¨ã‚­ãƒ£ãƒƒã‚·ãƒ¥ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ï¼‰"""
    try:
        if not os.path.exists("./data/economic_data.csv"):
            st.error("ãƒ‡ãƒ¼ã‚¿ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return pd.DataFrame()
            
        df = pd.read_csv("./data/economic_data.csv")
        df["date"] = pd.to_datetime(df["date"], dayfirst=True, errors='coerce')
        df = df.dropna(subset=['date'])
        df["data_tag"] = "None"
        
        # ã‚¤ãƒ™ãƒ³ãƒˆåã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ï¼ˆæœˆæƒ…å ±ãªã©ã‚’é™¤å»ã—ã¦æ­£è¦åŒ–ï¼‰
        def clean_event_name(event_name):
            import re
            if pd.isna(event_name):
                return ""
            # æœˆæƒ…å ±ã‚’é™¤å»ã—ã¦æ­£è¦åŒ–
            cleaned = re.sub(r'\s*\([A-Z][a-z]{2}\)\s*$', '', str(event_name))  # (Feb), (Jan)ãªã©ã‚’é™¤å»
            return cleaned.strip()
        
        df['cleaned_event'] = df['event'].apply(clean_event_name)
        
        # è©³ç´°ãªçµŒæ¸ˆæŒ‡æ¨™åˆ†é¡ï¼ˆåœ°åŸŸãƒ»æ™‚æœŸãƒ»ç¨®é¡ã‚’åŒºåˆ¥ï¼‰
        tag_patterns = {
            # CPIé–¢é€£ï¼ˆã‚ˆã‚Šè©³ç´°ã«åˆ†é¡ï¼‰
            'National CPI (YoY)': r'National.*CPI.*\(YoY\)',
            'National CPI (MoM)': r'National.*CPI.*\(MoM\)',
            'Tokyo CPI (YoY)': r'Tokyo.*CPI.*\(YoY\)',
            'Tokyo CPI (MoM)': r'Tokyo.*CPI.*\(MoM\)',
            'Tokyo CPI Ex Food & Energy (YoY)': r'Tokyo.*CPI.*Ex.*Food.*Energy.*\(YoY\)|CPI.*Tokyo.*Ex.*Food.*Energy.*\(YoY\)',
            'Tokyo CPI Ex Food & Energy (MoM)': r'Tokyo.*CPI.*Ex.*Food.*Energy.*\(MoM\)|CPI.*Tokyo.*Ex.*Food.*Energy.*\(MoM\)',
            'Core CPI (YoY)': r'Core.*CPI.*\(YoY\)',
            'Core CPI (MoM)': r'Core.*CPI.*\(MoM\)',
            'CPI (YoY)': r'CPI.*\(YoY\)|Consumer.*Price.*Index.*\(YoY\)',
            'CPI (MoM)': r'CPI.*\(MoM\)|Consumer.*Price.*Index.*\(MoM\)',
            
            # ä½å®…é–¢é€£
            'Housing Prices (YoY)': r'Housing.*Price.*\(YoY\)|HPI.*\(YoY\)|House.*Price.*\(YoY\)',
            'Housing Prices (MoM)': r'Housing.*Price.*\(MoM\)|HPI.*\(MoM\)|House.*Price.*\(MoM\)',
            'Building Permits': r'Building Permits|Construction.*Permits',
            'Housing Starts': r'Housing Starts|Home.*Starts',
            
            # å°å£²ãƒ»æ¶ˆè²»é–¢é€£
            'Retail Sales (YoY)': r'Retail Sales.*\(YoY\)',
            'Retail Sales (MoM)': r'Retail Sales.*\(MoM\)',
            'Consumer Confidence': r'Consumer Confidence|Consumer Sentiment',
            
            # é›‡ç”¨é–¢é€£
            'Employment Change': r'Employment Change|Nonfarm.*Payroll',
            'Unemployment Rate': r'Unemployment Rate',
            'Job Cuts (YoY)': r'Job.*Cuts.*\(YoY\)|Challenger.*Job.*Cuts.*\(YoY\)',
            'Jobless Claims': r'Initial.*Claims|Continuing.*Claims|Jobless.*Claims',
            
            # è£½é€ æ¥­ãƒ»PMI
            'Manufacturing PMI': r'Manufacturing.*PMI',
            'Services PMI': r'Services.*PMI|Service.*Sector.*PMI',
            'Composite PMI': r'Composite.*PMI',
            
            # é‡‘èãƒ»é‡‘åˆ©
            'Interest Rate': r'Interest Rate|Fed.*Rate|BoJ.*Rate|ECB.*Rate|BoE.*Rate|RBA.*Rate|FOMC|Bank Rate|Cash Rate',
            'Money Supply (YoY)': r'Money Supply.*\(YoY\)|M[123].*Money.*Supply.*\(YoY\)',
            'Money Supply (MoM)': r'Money Supply.*\(MoM\)|M[123].*Money.*Supply.*\(MoM\)',
            
            # è²¿æ˜“ãƒ»å•†å“
            'Trade Balance': r'Trade Balance|Current Account',
            'Commodity Prices (YoY)': r'Commodity.*Prices.*\(YoY\)',
            'Commodity Prices (MoM)': r'Commodity.*Prices.*\(MoM\)',
            
            # ç”£æ¥­ç”Ÿç”£
            'Industrial Production (YoY)': r'Industrial Production.*\(YoY\)',
            'Industrial Production (MoM)': r'Industrial Production.*\(MoM\)',
            
            # PPIé–¢é€£
            'PPI (YoY)': r'PPI.*\(YoY\)|Producer.*Price.*\(YoY\)',
            'PPI (MoM)': r'PPI.*\(MoM\)|Producer.*Price.*\(MoM\)',
            
            # GDPé–¢é€£
            'GDP (YoY)': r'GDP.*\(YoY\)',
            'GDP (QoQ)': r'GDP.*\(QoQ\)|GDP.*\(MoM\)',
            
            # ãã®ä»–
            'Factory Orders': r'Factory.*Orders|Manufacturing.*Orders',
            'Business Investment': r'Capital.*Expenditure|Business.*Investment|Capex',
            'Loans (YoY)': r'Loans.*\(YoY\)|Credit.*\(YoY\)'
        }
        
        # æŒ‡æ¨™ã‚’å„ªå…ˆåº¦é †ã«ãƒãƒƒãƒãƒ³ã‚°ï¼ˆç‰¹å®šã®ã‚‚ã®ã‹ã‚‰å…ˆã«ï¼‰
        for tag, pattern in tag_patterns.items():
            # ã¾ã ã‚¿ã‚°ä»˜ã‘ã•ã‚Œã¦ã„ãªã„è¡Œã®ã¿ãƒãƒƒãƒãƒ³ã‚°
            untagged_mask = df['data_tag'] == 'None'
            pattern_mask = df['event'].str.contains(pattern, na=False, case=False)
            final_mask = untagged_mask & pattern_mask
            df.loc[final_mask, 'data_tag'] = tag
        
        # ã¾ã ã‚¿ã‚°ä»˜ã‘ã•ã‚Œã¦ã„ãªã„ã‚‚ã®ã¯ã€ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã—ãŸã‚¤ãƒ™ãƒ³ãƒˆåã‚’ãã®ã¾ã¾ä½¿ç”¨
        untagged_mask = df['data_tag'] == 'None'
        df.loc[untagged_mask, 'data_tag'] = df.loc[untagged_mask, 'cleaned_event']
            
        # æ•°å€¤å¤‰æ›å‡¦ç†ï¼ˆå…¨ãƒ‡ãƒ¼ã‚¿ã«å¯¾ã—ã¦å®Ÿè¡Œï¼‰
        for col in ['actual', 'forecast', 'previous']:
            if col in df.columns:
                # æ•°å€¤å¤‰æ›å‡¦ç†
                def clean_numeric_value(value):
                    if pd.isna(value) or value == '':
                        return None
                    # æ–‡å­—åˆ—ã«å¤‰æ›
                    str_val = str(value)
                    # ã‚«ãƒ³ãƒã€%ã€Kã€Mã€Bã‚’é™¤å»
                    for char in [',', '%', 'K', 'M', 'B']:
                        str_val = str_val.replace(char, '')
                    # æ•°å€¤ã«å¤‰æ›
                    try:
                        return float(str_val)
                    except:
                        return None
                
                df[col] = df[col].apply(clean_numeric_value)
        
        return df
    except Exception as e:
        st.error(f"ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        return pd.DataFrame()

def clean_and_interpolate_data(series):
    """ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã¨ç·šå½¢è£œé–“"""
    try:
        # æ•°å€¤ã«å¤‰æ›ï¼ˆå…ƒã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’ä¿æŒï¼‰
        numeric_series = pd.to_numeric(series, errors='coerce')
        
        # 0å€¤ã‚’NaNã«å¤‰æ›ï¼ˆãŸã ã—ã€å®Ÿéš›ã«0ãŒæ„å‘³ã®ã‚ã‚‹å ´åˆã‚’è€ƒæ…®ï¼‰
        mask_zero = numeric_series == 0
        if mask_zero.sum() > 0:
            # å‰å¾Œã®å€¤ã¨æ¯”è¼ƒã—ã¦ç•°å¸¸ãª0å€¤ã‚’æ¤œå‡º
            zero_indices = numeric_series[mask_zero].index.tolist()
            
            for idx in zero_indices:
                try:
                    # ç¾åœ¨ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ä½ç½®ã‚’å–å¾—
                    current_pos = numeric_series.index.get_loc(idx)
                    
                    # å‰ã®å€¤ã‚’å–å¾—
                    prev_val = None
                    if current_pos > 0:
                        prev_data = numeric_series.iloc[:current_pos].dropna()
                        if len(prev_data) > 0:
                            prev_val = prev_data.iloc[-1]
                    
                    # æ¬¡ã®å€¤ã‚’å–å¾—
                    next_val = None
                    if current_pos < len(numeric_series) - 1:
                        next_data = numeric_series.iloc[current_pos+1:].dropna()
                        if len(next_data) > 0:
                            next_val = next_data.iloc[0]
                    
                    # å‰å¾Œã®å€¤ãŒ0ã§ãªã„å ´åˆã€0å€¤ã‚’NaNã«å¤‰æ›
                    if prev_val is not None and next_val is not None:
                        if prev_val != 0 and next_val != 0:
                            numeric_series.loc[idx] = pd.NA
                            
                except (IndexError, KeyError, ValueError):
                    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚¨ãƒ©ãƒ¼ã®å ´åˆã¯ã‚¹ã‚­ãƒƒãƒ—
                    continue
        
        # å‰ã®å€¤ã§ç©´åŸ‹ã‚ï¼ˆforward fillï¼‰ãã®å¾Œã€ç·šå½¢è£œé–“
        filled_series = numeric_series.ffill()
        # æ®‹ã£ãŸNaNå€¤ã¯ç·šå½¢è£œé–“
        interpolated_series = filled_series.interpolate(method='linear')
        
        return interpolated_series
        
    except Exception as e:
        # ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãŸå ´åˆã¯å…ƒã®ã‚·ãƒªãƒ¼ã‚ºã‚’æ•°å€¤å¤‰æ›ã®ã¿ã—ã¦è¿”ã™
        st.warning(f"ãƒ‡ãƒ¼ã‚¿è£œé–“ã§ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        return pd.to_numeric(series, errors='coerce')

def get_indicator_unit_group(tag, sample_values):
    """æŒ‡æ¨™ã®å˜ä½ã¨ã‚¹ã‚±ãƒ¼ãƒ«ã‚°ãƒ«ãƒ¼ãƒ—ã‚’åˆ¤å®šï¼ˆã‚¹ã‚±ãƒ¼ãƒ«ç´°åˆ†åŒ–ç‰ˆï¼‰"""
    # ã‚µãƒ³ãƒ—ãƒ«å€¤ã®ç¯„å›²ã‚’ç¢ºèª
    numeric_values = pd.to_numeric(sample_values, errors='coerce').dropna()
    if len(numeric_values) == 0:
        return "other", "ãã®ä»–"
    
    value_range = numeric_values.max() - numeric_values.min()
    avg_value = abs(numeric_values.mean())
    max_value = numeric_values.max()
    min_value = numeric_values.min()
    
    # ã‚ˆã‚Šå³å¯†ãªæŒ‡æ¨™åãƒ‘ã‚¿ãƒ¼ãƒ³ãƒãƒƒãƒãƒ³ã‚°
    tag_lower = tag.lower()
    
    # 1. PMIï¼ˆ50ãŒåŸºæº–ï¼‰ã‚’å„ªå…ˆ
    if 'pmi' in tag_lower:
        return "index_50", "PMI (50åŸºæº–)"
    
    # 2. å¤§è¦æ¨¡ãªçµŒæ¸ˆæŒ‡æ¨™
    if any(x in tag_lower for x in ['gdp', 'trade balance', 'current account']):
        if avg_value > 1000000:  # 100ä¸‡ä»¥ä¸Š
            return "billions", "åå„„å˜ä½"
        elif avg_value > 1000:
            return "millions", "ç™¾ä¸‡å˜ä½"
        else:
            # GDPæˆé•·ç‡ãªã©ã®å ´åˆ
            if max_value < 5:
                return "percentage_small", "ç‡ (0-5%)"
            elif max_value < 10:
                return "percentage_medium", "ç‡ (0-10%)"
            else:
                return "percentage_large", "ç‡ (10%+)"
    
    # 3. é›‡ç”¨ãƒ»åŠ´åƒçµ±è¨ˆ
    if any(x in tag_lower for x in ['claims', 'payroll', 'employment change', 'nonfarm']):
        if avg_value > 100000:  # 10ä¸‡ä»¥ä¸Š
            return "count_hundreds_k", "ä»¶æ•° (10ä¸‡)"
        elif avg_value > 1000:
            return "count_thousands", "ä»¶æ•° (åƒ)"
        else:
            return "count_units", "ä»¶æ•°"
    
    # 4. ç‡ãƒ»ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸æŒ‡æ¨™ã®ç´°åˆ†åŒ–
    percentage_patterns = [
        'rate', 'unemployment', 'interest', '(yoy)', '(mom)', '(qoq)',
        'inflation', 'change', 'growth'
    ]
    if any(pattern in tag_lower for pattern in percentage_patterns):
        if avg_value < 50:  # ä¸€èˆ¬çš„ãªç‡ã¯50%ä»¥ä¸‹
            # ã‚¹ã‚±ãƒ¼ãƒ«ã§ã•ã‚‰ã«ç´°åˆ†åŒ–
            if 'interest' in tag_lower or 'fed rate' in tag_lower or 'bank rate' in tag_lower:
                return "percentage_interest", "é‡‘åˆ© (0-5%)"
            elif 'unemployment' in tag_lower:
                return "percentage_unemployment", "å¤±æ¥­ç‡ (0-20%)"
            elif 'inflation' in tag_lower or 'cpi' in tag_lower:
                if min_value < -2:
                    return "percentage_inflation_neg", "ã‚¤ãƒ³ãƒ•ãƒ¬ç‡ (-5~+15%)"
                else:
                    return "percentage_inflation", "ã‚¤ãƒ³ãƒ•ãƒ¬ç‡ (0-10%)"
            elif max_value < 5:
                return "percentage_small", "ç‡ (0-5%)"
            elif max_value < 10:
                return "percentage_medium", "ç‡ (0-10%)"
            elif max_value < 20:
                return "percentage_large", "ç‡ (0-20%)"
            else:
                return "percentage_xlarge", "ç‡ (20%+)"
    
    # 5. ä¾¡æ ¼æŒ‡æ•°ï¼ˆCPIã€PPIç­‰ï¼‰
    if any(x in tag_lower for x in ['cpi', 'ppi', 'price index']):
        if avg_value > 50:  # æŒ‡æ•°ã¯é€šå¸¸50ä»¥ä¸Š
            return "index", "æŒ‡æ•°"
        else:
            # å¤‰åŒ–ç‡ã®å ´åˆ
            if max_value < 5:
                return "percentage_small", "ç‡ (0-5%)"
            else:
                return "percentage_medium", "ç‡ (0-10%)"
    
    # 6. è²©å£²ãƒ»ç”Ÿç”£é–¢é€£
    if any(x in tag_lower for x in ['sales', 'production', 'orders']):
        if avg_value > 1000000:
            return "millions", "ç™¾ä¸‡å˜ä½"
        elif avg_value > 1000:
            return "thousands", "åƒå˜ä½"
        else:
            if max_value < 5:
                return "percentage_small", "ç‡ (0-5%)"
            else:
                return "percentage_medium", "ç‡ (0-10%)"
    
    # 7. æ•°å€¤ç¯„å›²ã«ã‚ˆã‚‹åˆ†é¡ï¼ˆã‚ˆã‚Šå³å¯†ï¼‰
    if avg_value > 10000000:  # 1000ä¸‡ä»¥ä¸Š
        return "billions", "åå„„å˜ä½"
    elif avg_value > 1000000:  # 100ä¸‡ä»¥ä¸Š
        return "millions", "ç™¾ä¸‡å˜ä½"
    elif avg_value > 100000:  # 10ä¸‡ä»¥ä¸Š
        return "count_hundreds_k", "ä»¶æ•° (10ä¸‡)"
    elif avg_value > 10000:  # 1ä¸‡ä»¥ä¸Š
        return "thousands", "åƒå˜ä½"
    elif avg_value > 200:  # 200ä»¥ä¸Š
        return "index", "æŒ‡æ•°"
    elif avg_value > 30 and avg_value < 80 and value_range < 30:  # PMIç¯„å›²
        return "index_50", "æŒ‡æ•° (50åŸºæº–)"
    elif avg_value < 30:  # 30æœªæº€
        # ã‚¹ã‚±ãƒ¼ãƒ«ã§ç´°åˆ†åŒ–
        if max_value < 5:
            return "percentage_small", "ç‡ (0-5%)"
        elif max_value < 10:
            return "percentage_medium", "ç‡ (0-10%)"
        elif max_value < 20:
            return "percentage_large", "ç‡ (0-20%)"
        else:
            return "percentage_xlarge", "ç‡ (20%+)"
    else:
        return "other", "ãã®ä»–"

def create_currency_chart(df, currency, value_type):
    """é€šè²¨åˆ¥ãƒãƒ£ãƒ¼ãƒˆä½œæˆï¼ˆå‹•çš„ã‚¹ã‚±ãƒ¼ãƒ«ã‚°ãƒ«ãƒ¼ãƒ”ãƒ³ã‚°ï¼‰"""
    data = df[(df['currency'] == currency) & (df['data_tag'] != "None")]
    
    if data.empty:
        st.warning(f"{currency}ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return None
    
    # æŒ‡æ¨™ã”ã¨ã®çµ±è¨ˆæƒ…å ±ã‚’åé›†
    indicator_stats = {}
    for tag in sorted(data['data_tag'].unique()):
        tag_data = data[data['data_tag'] == tag].copy()
        if not tag_data.empty and value_type in tag_data.columns:
            numeric_values = pd.to_numeric(tag_data[value_type], errors='coerce').dropna()
            if len(numeric_values) > 0:
                indicator_stats[tag] = {
                    'min': numeric_values.min(),
                    'max': numeric_values.max(),
                    'mean': numeric_values.mean(),
                    'range': numeric_values.max() - numeric_values.min(),
                    'data': tag_data
                }
    
    # å‹•çš„ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆ
    scale_groups = create_dynamic_scale_groups(indicator_stats, tag)
    
    # å„ã‚¹ã‚±ãƒ¼ãƒ«ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ã«ãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆ
    return create_multi_scale_charts(data, currency, value_type, scale_groups, indicator_stats)

def create_single_axis_chart(data, currency, value_type, unit_group):
    """å˜è»¸ãƒãƒ£ãƒ¼ãƒˆä½œæˆ"""
    fig = go.Figure()
    colors = px.colors.qualitative.Set3 + px.colors.qualitative.Pastel1
    
    for i, tag in enumerate(sorted(data['data_tag'].unique())):
        tag_data = data[data['data_tag'] == tag].copy()
        if not tag_data.empty:
            # æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆ
            tag_data = tag_data.sort_values('date')
            
            # ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã¨è£œé–“
            cleaned_values = clean_and_interpolate_data(tag_data[value_type])
            
            # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨
            valid_mask = ~cleaned_values.isna()
            if valid_mask.any():
                valid_data = tag_data[valid_mask]
                valid_values = cleaned_values[valid_mask]
                
                # é‡è¦åº¦æƒ…å ±ã‚’è¿½åŠ 
                importance_info = valid_data['importance'].iloc[0] if 'importance' in valid_data.columns and len(valid_data) > 0 else 'unknown'
                importance_emoji = {'high': 'ğŸ”´', 'medium': 'ğŸŸ¡', 'low': 'ğŸŸ¢'}.get(importance_info, 'âšª')
                
                fig.add_trace(go.Scatter(
                    x=valid_data['date'],
                    y=valid_values,
                    mode='lines+markers',
                    name=f"{importance_emoji} {tag}",
                    line=dict(color=colors[i % len(colors)], width=2, shape='linear'),
                    marker=dict(size=4),
                    connectgaps=True,
                    hovertemplate=f'<b>{tag}</b><br>é‡è¦åº¦: {importance_info}<br>Date: %{{x}}<br>Value: %{{y:.2f}}<br><extra></extra>'
                ))
    
    # å˜ä½ã«å¿œã˜ãŸè»¸è¨­å®š
    yaxis_title = get_yaxis_title(unit_group)
    
    fig.update_layout(
        title=f"ğŸ›ï¸ {currency} Economic Indicators ({value_type.capitalize()})",
        xaxis_title="ğŸ“… Date",
        yaxis_title=yaxis_title,
        template="plotly_dark",
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        font=dict(color='white', family='Arial'),
        height=700,
        hovermode='x unified',
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        )
    )
    
    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='#333')
    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='#333')
    
    return fig

def create_dynamic_scale_groups(indicator_stats, tag_name_for_reference):
    """å‹•çš„ã«ã‚¹ã‚±ãƒ¼ãƒ«ã‚°ãƒ«ãƒ¼ãƒ—ã‚’ä½œæˆï¼ˆãƒãƒ©ãƒ³ã‚¹ç‰ˆï¼‰"""
    # æŒ‡æ¨™ã‚’ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«åˆ†é¡
    percentage_small = []  # 0-10%ç¨‹åº¦
    percentage_large = []  # 10%ä»¥ä¸Šã®ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸
    pmi_indicators = []    # PMIç³»ï¼ˆ50ä»˜è¿‘ï¼‰
    large_numbers = []     # 100ä»¥ä¸Šã®å¤§ããªæ•°å€¤
    negative_large = []    # å¤§ããªè² ã®å€¤
    
    for indicator, stats in indicator_stats.items():
        abs_max = max(abs(stats['min']), abs(stats['max']))
        
        # PMIç³»ã®åˆ¤å®š
        if ('PMI' in indicator or 'Composite' in indicator or 'Manufacturing' in indicator or 'Services' in indicator) and 40 <= abs_max <= 70:
            pmi_indicators.append(indicator)
        # å¤§ããªè² ã®å€¤ï¼ˆTrade Balanceãªã©ï¼‰
        elif stats['max'] < 0 and abs_max > 50:
            negative_large.append(indicator)
        # 100ä»¥ä¸Šã®å¤§ããªæ•°å€¤
        elif abs_max >= 100:
            large_numbers.append(indicator)
        # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ç³»ã®åˆ¤å®š
        elif abs_max <= 50:  # 50%ä»¥ä¸‹ã¯ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ã¨ã¿ãªã™
            if abs_max <= 10:
                percentage_small.append(indicator)
            else:
                percentage_large.append(indicator)
        else:
            # ãã®ä»–ã¯å¤§ããªæ•°å€¤ã«
            large_numbers.append(indicator)
    
    scale_groups = []
    
    # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ç³»å°ã‚°ãƒ«ãƒ¼ãƒ—ï¼ˆ0-10%ï¼‰
    if percentage_small:
        min_vals = [indicator_stats[ind]['min'] for ind in percentage_small]
        max_vals = [indicator_stats[ind]['max'] for ind in percentage_small]
        scale_groups.append({
            'indicators': percentage_small,
            'label': f"å°ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸: {min(min_vals):.1f}~{max(max_vals):.1f}%",
            'min': min(min_vals),
            'max': max(max_vals)
        })
    
    # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ç³»å¤§ã‚°ãƒ«ãƒ¼ãƒ—ï¼ˆ10%ä»¥ä¸Šï¼‰
    if percentage_large:
        min_vals = [indicator_stats[ind]['min'] for ind in percentage_large]
        max_vals = [indicator_stats[ind]['max'] for ind in percentage_large]
        scale_groups.append({
            'indicators': percentage_large,
            'label': f"å¤§ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸: {min(min_vals):.1f}~{max(max_vals):.1f}%",
            'min': min(min_vals),
            'max': max(max_vals)
        })
    
    # PMIç³»
    if pmi_indicators:
        min_vals = [indicator_stats[ind]['min'] for ind in pmi_indicators]
        max_vals = [indicator_stats[ind]['max'] for ind in pmi_indicators]
        scale_groups.append({
            'indicators': pmi_indicators,
            'label': f"PMIæŒ‡æ•°: {min(min_vals):.0f}~{max(max_vals):.0f}",
            'min': min(min_vals),
            'max': max(max_vals)
        })
    
    # å¤§ããªè² ã®å€¤
    if negative_large:
        min_vals = [indicator_stats[ind]['min'] for ind in negative_large]
        max_vals = [indicator_stats[ind]['max'] for ind in negative_large]
        scale_groups.append({
            'indicators': negative_large,
            'label': f"å¤§ããªè² ã®å€¤: {int(min(min_vals)):,}~{int(max(max_vals)):,}",
            'min': min(min_vals),
            'max': max(max_vals)
        })
    
    # å¤§ããªæ•°å€¤ï¼ˆã•ã‚‰ã«ã‚µãƒ–ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ï¼‰
    if large_numbers:
        # 100-1000ã¨ã€1000ä»¥ä¸Šã«åˆ†ã‘ã‚‹
        medium_large = []
        very_large = []
        
        for ind in large_numbers:
            abs_max = max(abs(indicator_stats[ind]['min']), abs(indicator_stats[ind]['max']))
            if abs_max < 1000:
                medium_large.append(ind)
            else:
                very_large.append(ind)
        
        if medium_large:
            min_vals = [indicator_stats[ind]['min'] for ind in medium_large]
            max_vals = [indicator_stats[ind]['max'] for ind in medium_large]
            scale_groups.append({
                'indicators': medium_large,
                'label': f"ä¸­è¦æ¨¡æ•°å€¤: {int(min(min_vals))}~{int(max(max_vals))}",
                'min': min(min_vals),
                'max': max(max_vals)
            })
        
        if very_large:
            min_vals = [indicator_stats[ind]['min'] for ind in very_large]
            max_vals = [indicator_stats[ind]['max'] for ind in very_large]
            scale_groups.append({
                'indicators': very_large,
                'label': f"å¤§è¦æ¨¡æ•°å€¤: {int(min(min_vals)):,}~{int(max(max_vals)):,}",
                'min': min(min_vals),
                'max': max(max_vals)
            })
    
    # ã‚¹ã‚±ãƒ¼ãƒ«ã®å°ã•ã„é †ã«ã‚½ãƒ¼ãƒˆ
    scale_groups.sort(key=lambda x: max(abs(x['min']), abs(x['max'])))
    
    return scale_groups

def create_multi_scale_charts(data, currency, value_type, scale_groups, indicator_stats):
    """ã‚¹ã‚±ãƒ¼ãƒ«ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ã«è¤‡æ•°ã®ãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆ"""
    charts = []
    
    for group in scale_groups:
        if not group['indicators']:
            continue
            
        # ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã®ãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆ
        fig = create_scale_group_chart(data, currency, value_type, group, indicator_stats)
        if fig:
            charts.append({
                'figure': fig,
                'unit_label': group['label'],
                'indicators': group['indicators'],
                'scale_min': group['min'],
                'scale_max': group['max']
            })
    
    return charts

def create_scale_group_chart(data, currency, value_type, group, indicator_stats):
    """ç‰¹å®šã®ã‚¹ã‚±ãƒ¼ãƒ«ã‚°ãƒ«ãƒ¼ãƒ—ã®ãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆ"""
    fig = go.Figure()
    colors = px.colors.qualitative.Set3 + px.colors.qualitative.Pastel1
    
    color_idx = 0
    for tag in sorted(group['indicators']):
        tag_data = data[data['data_tag'] == tag].copy()
        if not tag_data.empty:
            tag_data = tag_data.sort_values('date')
            cleaned_values = clean_and_interpolate_data(tag_data[value_type])
            valid_mask = ~cleaned_values.isna()
            
            if valid_mask.any():
                valid_data = tag_data[valid_mask]
                valid_values = cleaned_values[valid_mask]
                
                importance_info = valid_data['importance'].iloc[0] if 'importance' in valid_data.columns and len(valid_data) > 0 else 'unknown'
                importance_emoji = {'high': 'ğŸ”´', 'medium': 'ğŸŸ¡', 'low': 'ğŸŸ¢'}.get(importance_info, 'âšª')
                
                # æŒ‡æ¨™ã®çµ±è¨ˆæƒ…å ±ã‚’è¡¨ç¤º
                stats = indicator_stats.get(tag, {})
                hover_text = f"<b>{tag}</b><br>é‡è¦åº¦: {importance_info}<br>ç¯„å›²: {stats.get('min', 0):.2f}~{stats.get('max', 0):.2f}"
                
                fig.add_trace(go.Scatter(
                    x=valid_data['date'],
                    y=valid_values,
                    mode='lines+markers',
                    name=f"{importance_emoji} {tag}",
                    line=dict(color=colors[color_idx % len(colors)], width=2, shape='linear'),
                    marker=dict(size=4),
                    connectgaps=True,
                    hovertemplate=hover_text + "<br>Date: %{x}<br>Value: %{y:.2f}<br><extra></extra>"
                ))
                color_idx += 1
    
    # Yè»¸ã¯è‡ªå‹•ã‚¹ã‚±ãƒ¼ãƒ«ã«ä»»ã›ã‚‹ï¼ˆå›ºå®šã—ãªã„ï¼‰
    
    # å˜ä½ã‚’åˆ¤å®š
    unit_suffix = ""
    if all(indicator_stats.get(ind, {}).get('max', 0) < 100 for ind in group['indicators']):
        unit_suffix = " (%)"
    
    fig.update_layout(
        title=dict(
            text=f"ğŸ›ï¸ {currency} - {group['label']} ({value_type.capitalize()})",
            y=0.95,  # ã‚¿ã‚¤ãƒˆãƒ«ã‚’å°‘ã—ä¸‹ã«
            x=0.5,
            xanchor='center'
        ),
        xaxis_title="ğŸ“… Date",
        yaxis_title=f"ğŸ“Š Value{unit_suffix}",
        yaxis=dict(
            showgrid=True,
            gridwidth=1,
            gridcolor='#333'
        ),
        template="plotly_dark",
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        font=dict(color='white', family='Arial'),
        height=550,  # é«˜ã•ã‚’å°‘ã—å¢—ã‚„ã™
        hovermode='x unified',
        legend=dict(
            orientation="h",
            yanchor="top",
            y=-0.15,  # å‡¡ä¾‹ã‚’ã‚°ãƒ©ãƒ•ã®ä¸‹ã«ç§»å‹•
            xanchor="center",
            x=0.5
        ),
        margin=dict(t=80, b=120)  # ä¸Šä¸‹ã®ãƒãƒ¼ã‚¸ãƒ³ã‚’èª¿æ•´
    )
    
    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='#333')
    
    return fig

def create_multi_unit_charts(data, currency, value_type, indicator_groups):
    """å˜ä½ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ã«è¤‡æ•°ã®ãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆ"""
    charts = []
    
    # å„ªå…ˆé †ä½: percentage > index_50 > index > ãã®ä»–
    priority_order = ["percentage", "index_50", "index", "count_thousands", "thousands", "millions", "billions", "other"]
    sorted_groups = sorted(indicator_groups.keys(), key=lambda x: priority_order.index(x) if x in priority_order else len(priority_order))
    
    for unit_group in sorted_groups:
        group_info = indicator_groups[unit_group]
        if not group_info['indicators']:
            continue
            
        # ã‚°ãƒ«ãƒ¼ãƒ—ã”ã¨ã®ãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆ
        fig = create_unit_group_chart(data, currency, value_type, unit_group, group_info)
        if fig:
            charts.append({
                'figure': fig,
                'unit_group': unit_group,
                'unit_label': group_info['label'],
                'indicators': group_info['indicators']
            })
    
    return charts

def create_unit_group_chart(data, currency, value_type, unit_group, group_info):
    """ç‰¹å®šã®å˜ä½ã‚°ãƒ«ãƒ¼ãƒ—ã®ãƒãƒ£ãƒ¼ãƒˆã‚’ä½œæˆ"""
    fig = go.Figure()
    colors = px.colors.qualitative.Set3 + px.colors.qualitative.Pastel1
    
    color_idx = 0
    for tag in sorted(group_info['indicators']):
        tag_data = data[data['data_tag'] == tag].copy()
        if not tag_data.empty:
            tag_data = tag_data.sort_values('date')
            cleaned_values = clean_and_interpolate_data(tag_data[value_type])
            valid_mask = ~cleaned_values.isna()
            
            if valid_mask.any():
                valid_data = tag_data[valid_mask]
                valid_values = cleaned_values[valid_mask]
                
                importance_info = valid_data['importance'].iloc[0] if 'importance' in valid_data.columns and len(valid_data) > 0 else 'unknown'
                importance_emoji = {'high': 'ğŸ”´', 'medium': 'ğŸŸ¡', 'low': 'ğŸŸ¢'}.get(importance_info, 'âšª')
                
                fig.add_trace(go.Scatter(
                    x=valid_data['date'],
                    y=valid_values,
                    mode='lines+markers',
                    name=f"{importance_emoji} {tag}",
                    line=dict(color=colors[color_idx % len(colors)], width=2, shape='linear'),
                    marker=dict(size=4),
                    connectgaps=True,
                    hovertemplate=f'<b>{tag}</b><br>é‡è¦åº¦: {importance_info}<br>Date: %{{x}}<br>Value: %{{y:.2f}}<br><extra></extra>'
                ))
                color_idx += 1
    
    # å˜ä½ã«å¿œã˜ãŸè»¸è¨­å®š
    yaxis_title = get_yaxis_title(unit_group)
    yaxis_config = get_yaxis_config(unit_group)
    
    # ã‚¹ã‚±ãƒ¼ãƒ«æƒ…å ±ã‚’å«ã‚€ã‚¿ã‚¤ãƒˆãƒ«ã‚’ä½œæˆ
    scale_info = ""
    if unit_group.startswith("percentage_"):
        if "small" in unit_group:
            scale_info = " (0-5%ã‚¹ã‚±ãƒ¼ãƒ«)"
        elif "medium" in unit_group:
            scale_info = " (0-10%ã‚¹ã‚±ãƒ¼ãƒ«)"
        elif "large" in unit_group and "xlarge" not in unit_group:
            scale_info = " (0-20%ã‚¹ã‚±ãƒ¼ãƒ«)"
        elif "xlarge" in unit_group:
            scale_info = " (20%+ã‚¹ã‚±ãƒ¼ãƒ«)"
    
    fig.update_layout(
        title=f"ğŸ›ï¸ {currency} - {group_info['label']}{scale_info} ({value_type.capitalize()})",
        xaxis_title="ğŸ“… Date",
        yaxis_title=yaxis_title,
        template="plotly_dark",
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        font=dict(color='white', family='Arial'),
        height=500,  # å°‘ã—ä½ã‚ã«è¨­å®š
        hovermode='x unified',
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        ),
        **yaxis_config
    )
    
    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='#333')
    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='#333')
    
    return fig

def create_dual_axis_chart(data, currency, value_type, indicator_groups):
    """ãƒ‡ãƒ¥ã‚¢ãƒ«è»¸ãƒãƒ£ãƒ¼ãƒˆä½œæˆ"""
    fig = go.Figure()
    colors = px.colors.qualitative.Set3 + px.colors.qualitative.Pastel1
    
    # ä¸»è¦ã‚°ãƒ«ãƒ¼ãƒ—ã¨å‰¯ã‚°ãƒ«ãƒ¼ãƒ—ã‚’æ±ºå®šï¼ˆã‚ˆã‚Šé©åˆ‡ãªå„ªå…ˆé †ä½ï¼‰
    group_keys = list(indicator_groups.keys())
    
    # å„ªå…ˆé †ä½: percentage > index_50 > index > ãã®ä»–
    priority_order = ["percentage", "index_50", "index", "count_thousands", "thousands", "millions", "billions", "other"]
    sorted_groups = sorted(group_keys, key=lambda x: priority_order.index(x) if x in priority_order else len(priority_order))
    
    primary_group = sorted_groups[0]
    secondary_group = sorted_groups[1] if len(sorted_groups) > 1 else sorted_groups[0]
    
    # è‰²ã®ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹
    color_idx = 0
    
    # ç¬¬1è»¸ã®ãƒ‡ãƒ¼ã‚¿
    for tag in indicator_groups[primary_group]['indicators']:
        tag_data = data[data['data_tag'] == tag].copy()
        if not tag_data.empty:
            tag_data = tag_data.sort_values('date')
            cleaned_values = clean_and_interpolate_data(tag_data[value_type])
            valid_mask = ~cleaned_values.isna()
            
            if valid_mask.any():
                valid_data = tag_data[valid_mask]
                valid_values = cleaned_values[valid_mask]
                
                importance_info = valid_data['importance'].iloc[0] if 'importance' in valid_data.columns and len(valid_data) > 0 else 'unknown'
                importance_emoji = {'high': 'ğŸ”´', 'medium': 'ğŸŸ¡', 'low': 'ğŸŸ¢'}.get(importance_info, 'âšª')
                
                fig.add_trace(go.Scatter(
                    x=valid_data['date'],
                    y=valid_values,
                    mode='lines+markers',
                    name=f"{importance_emoji} {tag}",
                    line=dict(color=colors[color_idx % len(colors)], width=2, shape='linear'),
                    marker=dict(size=4),
                    connectgaps=True,
                    yaxis='y',
                    hovertemplate=f'<b>{tag}</b><br>é‡è¦åº¦: {importance_info}<br>Date: %{{x}}<br>Value: %{{y:.2f}}<br><extra></extra>'
                ))
                color_idx += 1
    
    # ç¬¬2è»¸ã®ãƒ‡ãƒ¼ã‚¿
    for tag in indicator_groups[secondary_group]['indicators']:
        if tag in indicator_groups[primary_group]['indicators']:
            continue  # æ—¢ã«è¿½åŠ æ¸ˆã¿
            
        tag_data = data[data['data_tag'] == tag].copy()
        if not tag_data.empty:
            tag_data = tag_data.sort_values('date')
            cleaned_values = clean_and_interpolate_data(tag_data[value_type])
            valid_mask = ~cleaned_values.isna()
            
            if valid_mask.any():
                valid_data = tag_data[valid_mask]
                valid_values = cleaned_values[valid_mask]
                
                importance_info = valid_data['importance'].iloc[0] if 'importance' in valid_data.columns and len(valid_data) > 0 else 'unknown'
                importance_emoji = {'high': 'ğŸ”´', 'medium': 'ğŸŸ¡', 'low': 'ğŸŸ¢'}.get(importance_info, 'âšª')
                
                fig.add_trace(go.Scatter(
                    x=valid_data['date'],
                    y=valid_values,
                    mode='lines+markers',
                    name=f"{importance_emoji} {tag} (å³è»¸)",
                    line=dict(color=colors[color_idx % len(colors)], width=2, shape='linear', dash='dash'),
                    marker=dict(size=4, symbol='diamond'),
                    connectgaps=True,
                    yaxis='y2',
                    hovertemplate=f'<b>{tag}</b><br>é‡è¦åº¦: {importance_info}<br>Date: %{{x}}<br>Value: %{{y:.2f}}<br><extra></extra>'
                ))
                color_idx += 1
    
    # ãƒ‡ãƒ¥ã‚¢ãƒ«è»¸ãƒ¬ã‚¤ã‚¢ã‚¦ãƒˆ
    fig.update_layout(
        title=f"ğŸ›ï¸ {currency} Economic Indicators - Multi-Scale ({value_type.capitalize()})",
        xaxis_title="ğŸ“… Date",
        yaxis=dict(
            title=f"ğŸ“Š {indicator_groups[primary_group]['label']}",
            side="left",
            showgrid=True,
            gridwidth=1,
            gridcolor='#333'
        ),
        yaxis2=dict(
            title=f"ğŸ“ˆ {indicator_groups[secondary_group]['label']}",
            side="right",
            overlaying="y",
            showgrid=False
        ),
        template="plotly_dark",
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        font=dict(color='white', family='Arial'),
        height=700,
        hovermode='x unified',
        legend=dict(
            orientation="h",
            yanchor="bottom",
            y=1.02,
            xanchor="right",
            x=1
        )
    )
    
    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='#333')
    
    return fig

def get_yaxis_title(unit_group):
    """å˜ä½ã‚°ãƒ«ãƒ¼ãƒ—ã«å¿œã˜ãŸYè»¸ã‚¿ã‚¤ãƒˆãƒ«ã‚’å–å¾—"""
    titles = {
        "percentage": "ğŸ“Š ç‡ (%)",
        "percentage_small": "ğŸ“Š ç‡ (0-5%)",
        "percentage_medium": "ğŸ“Š ç‡ (0-10%)",
        "percentage_large": "ğŸ“Š ç‡ (0-20%)",
        "percentage_xlarge": "ğŸ“Š ç‡ (20%+)",
        "percentage_interest": "ğŸ“Š é‡‘åˆ© (%)",
        "percentage_unemployment": "ğŸ“Š å¤±æ¥­ç‡ (%)",
        "percentage_inflation": "ğŸ“Š ã‚¤ãƒ³ãƒ•ãƒ¬ç‡ (%)",
        "percentage_inflation_neg": "ğŸ“Š ã‚¤ãƒ³ãƒ•ãƒ¬ç‡ (%)",
        "index": "ğŸ“ˆ æŒ‡æ•°",
        "index_50": "ğŸ“Š PMI/æŒ‡æ•° (50åŸºæº–)",
        "billions": "ğŸ“ˆ åå„„å˜ä½",
        "millions": "ğŸ“ˆ ç™¾ä¸‡å˜ä½",
        "count_hundreds_k": "ğŸ“Š ä»¶æ•° (10ä¸‡)",
        "count_thousands": "ğŸ“Š ä»¶æ•° (åƒ)",
        "thousands": "ğŸ“Š åƒå˜ä½",
        "count_units": "ğŸ“Š ä»¶æ•°",
        "other": "ğŸ“Š å€¤"
    }
    return titles.get(unit_group, "ğŸ“Š å€¤")

def create_indicator_chart(df, indicator, value_type):
    """æŒ‡æ¨™åˆ¥ãƒãƒ£ãƒ¼ãƒˆä½œæˆï¼ˆçµ±ä¸€ã‚¹ã‚±ãƒ¼ãƒ«ï¼‰"""
    data = df[df['data_tag'] == indicator]
    
    if data.empty:
        st.warning(f"{indicator}ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
        return None
    
    # æŒ‡æ¨™ã®å˜ä½ã‚’åˆ¤å®šï¼ˆã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰ï¼‰
    sample_values = data[value_type].head(50)
    unit_group, unit_label = get_indicator_unit_group(indicator, sample_values)
    
    fig = go.Figure()
    colors = px.colors.qualitative.Set2 + px.colors.qualitative.Dark2
    
    for i, currency in enumerate(sorted([str(c) for c in data['currency'].dropna().unique()])):
        currency_data = data[data['currency'] == currency].copy()
        if not currency_data.empty:
            # æ—¥ä»˜ã§ã‚½ãƒ¼ãƒˆ
            currency_data = currency_data.sort_values('date')
            
            # ãƒ‡ãƒ¼ã‚¿ã®å‰å‡¦ç†ã¨è£œé–“
            cleaned_values = clean_and_interpolate_data(currency_data[value_type])
            
            # æœ‰åŠ¹ãªãƒ‡ãƒ¼ã‚¿ã®ã¿ä½¿ç”¨
            valid_mask = ~cleaned_values.isna()
            if valid_mask.any():
                valid_data = currency_data[valid_mask]
                valid_values = cleaned_values[valid_mask]
                
                # é‡è¦åº¦æƒ…å ±ã‚’è¿½åŠ 
                importance_info = valid_data['importance'].iloc[0] if 'importance' in valid_data.columns and len(valid_data) > 0 else 'unknown'
                importance_emoji = {'high': 'ğŸ”´', 'medium': 'ğŸŸ¡', 'low': 'ğŸŸ¢'}.get(importance_info, 'âšª')
                
                fig.add_trace(go.Scatter(
                    x=valid_data['date'],
                    y=valid_values,
                    mode='lines+markers',
                    name=f"{importance_emoji} {currency}",
                    line=dict(color=colors[i % len(colors)], width=3, shape='linear'),
                    marker=dict(size=5),
                    connectgaps=True,  # ã‚®ãƒ£ãƒƒãƒ—ã‚’æ¥ç¶š
                    hovertemplate=f'<b>{currency}</b><br>é‡è¦åº¦: {importance_info}<br>Date: %{{x}}<br>Value: %{{y:.2f}}<br><extra></extra>'
                ))
    
    # å˜ä½ã«å¿œã˜ãŸYè»¸ã‚¿ã‚¤ãƒˆãƒ«
    yaxis_title = get_yaxis_title(unit_group)
    
    # å˜ä½ã‚°ãƒ«ãƒ¼ãƒ—åˆ¥ã®è»¸è¨­å®š
    yaxis_config = get_yaxis_config(unit_group)
    
    fig.update_layout(
        title=dict(
            text=f"ğŸ“Š {indicator} Cross-Currency Comparison ({value_type.capitalize()})",
            y=0.95,
            x=0.5,
            xanchor='center'
        ),
        xaxis_title="ğŸ“… Date",
        yaxis_title=yaxis_title,
        template="plotly_dark",
        plot_bgcolor='rgba(0,0,0,0)',
        paper_bgcolor='rgba(0,0,0,0)',
        font=dict(color='white', family='Arial'),
        height=750,  # é«˜ã•ã‚’å°‘ã—å¢—ã‚„ã™
        hovermode='x unified',
        legend=dict(
            orientation="h",
            yanchor="top",
            y=-0.15,
            xanchor="center",
            x=0.5
        ),
        margin=dict(t=80, b=120),
        **yaxis_config
    )
    
    fig.update_xaxes(showgrid=True, gridwidth=1, gridcolor='#333')
    fig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='#333')
    
    return fig

def get_yaxis_config(unit_group):
    """å˜ä½ã‚°ãƒ«ãƒ¼ãƒ—ã«å¿œã˜ãŸYè»¸è¨­å®šã‚’å–å¾—"""
    base_config = {
        "yaxis": dict(
            showgrid=True,
            gridwidth=1,
            gridcolor='#333'
        )
    }
    
    # ãƒ‘ãƒ¼ã‚»ãƒ³ãƒ†ãƒ¼ã‚¸ç³»ã®è¨­å®šï¼ˆç¯„å›²å›ºå®šã¯ã—ãªã„ï¼‰
    if unit_group.startswith("percentage"):
        config = base_config.copy()
        config["yaxis"]["ticksuffix"] = "%"
        return config
    
    elif unit_group == "index_50":
        return {
            "yaxis": dict(
                showgrid=True,
                gridwidth=1,
                gridcolor='#333'
            ),
            "shapes": [
                dict(
                    type="line",
                    x0=0, x1=1,
                    y0=50, y1=50,
                    xref="paper",
                    line=dict(color="orange", width=1, dash="dash")
                )
            ]
        }
    elif unit_group in ["count_thousands", "thousands", "count_units"]:
        return {
            "yaxis": dict(
                tickformat=",",
                showgrid=True,
                gridwidth=1,
                gridcolor='#333'
            )
        }
    elif unit_group in ["count_hundreds_k"]:
        return {
            "yaxis": dict(
                tickformat=".1f",
                ticksuffix="ä¸‡",
                showgrid=True,
                gridwidth=1,
                gridcolor='#333'
            )
        }
    elif unit_group in ["millions", "billions"]:
        return {
            "yaxis": dict(
                tickformat=".2s",  # Scientific notation
                showgrid=True,
                gridwidth=1,
                gridcolor='#333'
            )
        }
    else:
        return base_config

def get_indicators_in_all_currencies(df):
    """å…¨é€šè²¨ã§æƒã£ã¦ã„ã‚‹çµŒæ¸ˆæŒ‡æ¨™ã‚’å–å¾—ï¼ˆé¡ä¼¼æŒ‡æ¨™å«ã‚€ï¼‰"""
    # åˆ©ç”¨å¯èƒ½ãªé€šè²¨ã‚’å–å¾—
    all_currencies = sorted([str(c) for c in df['currency'].dropna().unique()])
    
    # é¡ä¼¼æŒ‡æ¨™ã®ãƒãƒƒãƒ”ãƒ³ã‚°ï¼ˆæ¯”è¼ƒå¯èƒ½ã¨ã¿ãªã™æŒ‡æ¨™ç¾¤ï¼‰
    similar_indicators = {
        'CPI': ['CPI (YoY)', 'National CPI (YoY)', 'Core CPI (YoY)'],
        'CPI_MoM': ['CPI (MoM)', 'National CPI (MoM)', 'Core CPI (MoM)'],
        'Tokyo_CPI': ['Tokyo CPI (YoY)', 'CPI (YoY)'],  # æ±äº¬CPIã¨å…¨å›½CPIã¯æ¯”è¼ƒå¯èƒ½
        'Building_Permits': ['Building Permits', 'Housing Starts'],  # å»ºè¨­é–¢é€£
        'Factory_Orders': ['Factory Orders', 'Industrial Production (MoM)', 'Industrial Production (YoY)'],  # è£½é€ æ¥­é–¢é€£
        'Housing_Prices': ['Housing Prices (MoM)', 'Housing Prices (YoY)'],
        'PPI': ['PPI (MoM)', 'PPI (YoY)'],  # ç”Ÿç”£è€…ç‰©ä¾¡
        'Retail_Sales': ['Retail Sales (MoM)', 'Retail Sales (YoY)']
    }
    
    # æŒ‡æ¨™ã”ã¨ã«ã©ã®é€šè²¨ã§åˆ©ç”¨å¯èƒ½ã‹ã‚’ç¢ºèª
    indicator_currency_map = {}
    for indicator in df['data_tag'].unique():
        if indicator != "None":
            indicator_currencies = set(df[df['data_tag'] == indicator]['currency'].dropna().unique())
            indicator_currency_map[indicator] = indicator_currencies
    
    # é¡ä¼¼æŒ‡æ¨™ã‚°ãƒ«ãƒ¼ãƒ—ã§é€šè²¨ã‚«ãƒãƒ¬ãƒƒã‚¸ã‚’ãƒã‚§ãƒƒã‚¯
    group_coverage = {}
    for group_name, indicators in similar_indicators.items():
        covered_currencies = set()
        for indicator in indicators:
            if indicator in indicator_currency_map:
                covered_currencies.update(indicator_currency_map[indicator])
        
        if len(covered_currencies) == len(all_currencies):
            # ã“ã®ã‚°ãƒ«ãƒ¼ãƒ—ã¯å…¨é€šè²¨ã‚’ã‚«ãƒãƒ¼ã—ã¦ã„ã‚‹
            for indicator in indicators:
                if indicator in indicator_currency_map:
                    group_coverage[indicator] = covered_currencies
    
    # å®Œå…¨ä¸€è‡´ã®æŒ‡æ¨™ã‚‚è¿½åŠ 
    exact_match_indicators = []
    for indicator, currencies in indicator_currency_map.items():
        if len(currencies) == len(all_currencies):
            exact_match_indicators.append(indicator)
    
    # é¡ä¼¼æŒ‡æ¨™ã¨å®Œå…¨ä¸€è‡´æŒ‡æ¨™ã‚’çµ±åˆ
    full_coverage_indicators = list(set(exact_match_indicators + list(group_coverage.keys())))
    
    return sorted(full_coverage_indicators), all_currencies

def main():
    # ãƒ¡ã‚¤ãƒ³ã‚¿ã‚¤ãƒˆãƒ«
    st.markdown('<h1 class="main-header">ğŸ“Š Economic Data Dashboard</h1>', unsafe_allow_html=True)
    
    # ãƒ‡ãƒ¼ã‚¿æ›´æ–°ãƒã‚§ãƒƒã‚¯
    update_data_file()
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰
    with st.spinner('ğŸ“¥ ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿ä¸­...'):
        df = load_data()
    
    if df.empty:
        st.error("âŒ ãƒ‡ãƒ¼ã‚¿ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ")
        return
    
    # 5é€šè²¨ãƒ•ãƒ«ã‚«ãƒãƒ¬ãƒƒã‚¸æŒ‡æ¨™ã®æƒ…å ±
    full_coverage_indicators, all_currencies = get_indicators_in_all_currencies(df)
    
    # ãƒ‡ãƒ¼ã‚¿çµ±è¨ˆï¼ˆè±Šå¯Œãªæƒ…å ±è¡¨ç¤ºï¼‰
    col1, col2, col3, col4, col5, col6 = st.columns(6)
    with col1:
        st.metric("ğŸ“‹ ç·ãƒ‡ãƒ¼ã‚¿æ•°", f"{len(df):,}")
    with col2:
        st.metric("ğŸ›ï¸ é€šè²¨æ•°", len(df['currency'].unique()))
    with col3:
        st.metric("ğŸ“Š çµŒæ¸ˆæŒ‡æ¨™æ•°", len([tag for tag in df['data_tag'].unique() if tag != "None"]))
    with col4:
        st.metric("ğŸŒ å…¨é€šè²¨æŒ‡æ¨™", len(full_coverage_indicators))
    with col5:
        st.metric("ğŸ“… ãƒ‡ãƒ¼ã‚¿æœŸé–“", f"{df['date'].min().year} - {df['date'].max().year}")
    with col6:
        # ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°æ™‚åˆ»ã‚’è¡¨ç¤º
        data_file = "./data/economic_data.csv"
        if os.path.exists(data_file):
            file_time = datetime.fromtimestamp(os.path.getmtime(data_file))
            st.metric("ğŸ”„ ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°", f"{file_time.strftime('%m-%d %H:%M')}")
        else:
            st.metric("ğŸ”„ ãƒ•ã‚¡ã‚¤ãƒ«æ›´æ–°", "æœªå–å¾—")
    
    # é‡è¦åº¦åˆ†å¸ƒã‚’è¡¨ç¤º
    if 'importance' in df.columns:
        st.markdown("### ğŸ¯ é‡è¦åº¦åˆ†å¸ƒ")
        importance_counts = df['importance'].value_counts()
        col1, col2, col3 = st.columns(3)
        
        with col1:
            high_count = importance_counts.get('high', 0)
            st.metric("ğŸ”´ é«˜é‡è¦åº¦", f"{high_count:,}ä»¶")
        with col2:
            medium_count = importance_counts.get('medium', 0)
            st.metric("ğŸŸ¡ ä¸­é‡è¦åº¦", f"{medium_count:,}ä»¶")
        with col3:
            low_count = importance_counts.get('low', 0)
            st.metric("ğŸŸ¢ ä½é‡è¦åº¦", f"{low_count:,}ä»¶")
    
    # åˆ©ç”¨å¯èƒ½ãªæŒ‡æ¨™ã®ä¸€è¦§è¡¨ç¤º
    with st.expander("ğŸ“‹ åˆ©ç”¨å¯èƒ½ãªçµŒæ¸ˆæŒ‡æ¨™ä¸€è¦§"):
        indicators = sorted([tag for tag in df['data_tag'].unique() if tag != "None"])
        indicator_counts = df[df['data_tag'] != "None"]['data_tag'].value_counts()
        
        cols = st.columns(3)
        for i, indicator in enumerate(indicators):
            with cols[i % 3]:
                st.write(f"â€¢ **{indicator}**: {indicator_counts.get(indicator, 0):,} records")
    
    # ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã«é–¢ã™ã‚‹èª¬æ˜
    with st.expander("ğŸ”§ ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã«ã¤ã„ã¦"):
        st.markdown("""
        **ğŸ“ˆ ã‚°ãƒ©ãƒ•ã®æ»‘ã‚‰ã‹ã•æ”¹å–„:**
        - **ç•°å¸¸ãª0å€¤ã®æ¤œå‡º**: å‰å¾Œã®å€¤ã¨æ¯”è¼ƒã—ã¦ç•°å¸¸ãª0å€¤ã‚’è‡ªå‹•æ¤œå‡º
        - **å‰ã®å€¤ã§ç©´åŸ‹ã‚**: æ¬ æå€¤ã‚’å‰ã®å€¤ã§è£œå®Œï¼ˆForward Fillï¼‰
        - **ç·šå½¢è£œé–“**: æ®‹ã£ãŸæ¬ æå€¤ã¯ç·šå½¢è£œé–“ã§æ»‘ã‚‰ã‹ã«æ¥ç¶š
        - **ã‚®ãƒ£ãƒƒãƒ—æ¥ç¶š**: `connectgaps=True`ã§ãƒ‡ãƒ¼ã‚¿ã®æ–­çµ¶ã‚’è‡ªç„¶ã«æ¥ç¶š
        
        **ğŸ¯ åŠ¹æœ:**
        - æŠ˜ã‚Œç·šã‚°ãƒ©ãƒ•ã®ä¸è‡ªç„¶ãª0ã¸ã®æ€¥é™ä¸‹ã‚’é˜²æ­¢
        - ãƒ‡ãƒ¼ã‚¿ã®é€£ç¶šæ€§ã‚’ä¿æŒã—ã¦ãƒˆãƒ¬ãƒ³ãƒ‰ã‚’æ˜ç¢ºã«è¡¨ç¤º
        - ã‚ˆã‚Šè¦‹ã‚„ã™ãåˆ†æã—ã‚„ã™ã„ã‚°ãƒ©ãƒ•ã‚’å®Ÿç¾
        """)
    
    # å˜ä½ãƒ»ã‚¹ã‚±ãƒ¼ãƒ«åˆ†ææƒ…å ±
    with st.expander("ğŸ“ å˜ä½ãƒ»ã‚¹ã‚±ãƒ¼ãƒ«åˆ†æã«ã¤ã„ã¦"):
        st.markdown("""
        **ğŸ“Š ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆè»¸ç®¡ç†:**
        - **è‡ªå‹•å˜ä½æ¤œå‡º**: æŒ‡æ¨™åã¨æ•°å€¤ç¯„å›²ã‹ã‚‰æœ€é©ãªå˜ä½ã‚’è‡ªå‹•åˆ¤å®š
        - **ãƒ‡ãƒ¥ã‚¢ãƒ«è»¸è¡¨ç¤º**: ç•°ãªã‚‹ã‚¹ã‚±ãƒ¼ãƒ«ã®æŒ‡æ¨™ã‚’å·¦å³è»¸ã§åˆ†é›¢è¡¨ç¤º
        - **é©åˆ‡ãªæ•°å€¤ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ**: å„å˜ä½ã«å¿œã˜ãŸè¦‹ã‚„ã™ã„è¡¨ç¤ºå½¢å¼
        
        **ğŸ”§ å¯¾å¿œå˜ä½ã‚¿ã‚¤ãƒ—:**
        - ğŸ“Š **ç‡ (%)**: é‡‘åˆ©ã€å¤±æ¥­ç‡ã€ã‚¤ãƒ³ãƒ•ãƒ¬ç‡ãªã©ï¼ˆ%è¡¨ç¤ºï¼‰
        - ğŸ“ˆ **æŒ‡æ•°**: CPIã€PPIç­‰ã®ä¾¡æ ¼æŒ‡æ•°ï¼ˆãã®ã¾ã¾è¡¨ç¤ºï¼‰
        - ğŸ“Š **PMI (50åŸºæº–)**: è£½é€ æ¥­ãƒ»ã‚µãƒ¼ãƒ“ã‚¹æ¥­PMIï¼ˆ50åŸºæº–ç·šä»˜ãï¼‰
        - ğŸ“Š **ä»¶æ•° (åƒ)**: é›‡ç”¨çµ±è¨ˆã€è«‹æ±‚ä»¶æ•°ï¼ˆåƒå˜ä½ãƒ»ã‚«ãƒ³ãƒåŒºåˆ‡ã‚Šï¼‰
        - ğŸ“ˆ **å¤§è¦æ¨¡æ•°å€¤**: GDPã€è²¿æ˜“åæ”¯ï¼ˆç§‘å­¦è¨˜æ³•è¡¨ç¤ºï¼‰
        
        **ğŸ’¡ ãƒ‡ãƒ¥ã‚¢ãƒ«è»¸ã®æ´»ç”¨:**
        - å·¦è»¸ï¼ˆå®Ÿç·šï¼‰: ä¸»è¦æŒ‡æ¨™ã‚°ãƒ«ãƒ¼ãƒ—
        - å³è»¸ï¼ˆç ´ç·šãƒ»ãƒ€ã‚¤ãƒ¤ãƒ¢ãƒ³ãƒ‰ï¼‰: ç•°ãªã‚‹ã‚¹ã‚±ãƒ¼ãƒ«ã®æŒ‡æ¨™
        - è¦–è¦šçš„åŒºåˆ¥ã§æ¯”è¼ƒåˆ†æã‚’åŠ¹ç‡åŒ–
        """)
    
    # ã‚¹ã‚±ãƒ¼ãƒ«åˆ†æçµæœã®è¡¨ç¤º
    if not df.empty:
        with st.expander("ğŸ” ç¾åœ¨ã®ãƒ‡ãƒ¼ã‚¿ã®ã‚¹ã‚±ãƒ¼ãƒ«åˆ†æ"):
            scale_analysis = {}
            sample_size = min(1000, len(df))
            sample_df = df.sample(n=sample_size) if len(df) > sample_size else df
            
            for tag in sample_df['data_tag'].unique():
                if tag != "None":
                    tag_data = sample_df[sample_df['data_tag'] == tag]
                    if not tag_data.empty:
                        for value_type in ['actual', 'forecast']:
                            if value_type in tag_data.columns:
                                sample_values = tag_data[value_type].head(20)
                                unit_group, unit_label = get_indicator_unit_group(tag, sample_values)
                                
                                if unit_group not in scale_analysis:
                                    scale_analysis[unit_group] = {'label': unit_label, 'indicators': set()}
                                scale_analysis[unit_group]['indicators'].add(tag)
            
            for unit_group, info in scale_analysis.items():
                st.write(f"**{info['label']}**: {len(info['indicators'])}ç¨®é¡")
                indicators_list = sorted(list(info['indicators']))[:5]  # æœ€åˆã®5ã¤ã‚’è¡¨ç¤º
                for indicator in indicators_list:
                    st.write(f"  â€¢ {indicator}")
                if len(info['indicators']) > 5:
                    st.write(f"  â€¢ ... ä»–{len(info['indicators']) - 5}ç¨®é¡")
    
    st.markdown("---")
    
    # ã‚µã‚¤ãƒ‰ãƒãƒ¼
    st.sidebar.title("âš™ï¸ ãƒ€ãƒƒã‚·ãƒ¥ãƒœãƒ¼ãƒ‰è¨­å®š")
    
    # ãƒ‡ãƒ¼ã‚¿æ›´æ–°ãƒœã‚¿ãƒ³
    if st.sidebar.button("ğŸ”„ æœ€æ–°ãƒ‡ãƒ¼ã‚¿å–å¾—", help="æœ€æ–°ã®çµŒæ¸ˆãƒ‡ãƒ¼ã‚¿ã‚’æ‰‹å‹•ã§å–å¾—ã—ã¾ã™"):
        with st.spinner("ğŸ”„ æœ€æ–°ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­..."):
            # ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã‚’ã‚¯ãƒªã‚¢ã—ã¦å¼·åˆ¶æ›´æ–°
            load_data.clear()
            # ãƒ•ã‚¡ã‚¤ãƒ«ã®ã‚¿ã‚¤ãƒ ã‚¹ã‚¿ãƒ³ãƒ—ã‚’å¤ãã—ã¦å¼·åˆ¶æ›´æ–°
            data_file = "./data/economic_data.csv"
            if os.path.exists(data_file):
                old_time = time.time() - (7 * 60 * 60)  # 7æ™‚é–“å‰ã«è¨­å®š
                os.utime(data_file, (old_time, old_time))
            update_data_file()
            st.rerun()  # ãƒšãƒ¼ã‚¸ã‚’ãƒªãƒ•ãƒ¬ãƒƒã‚·ãƒ¥
    
    # ã‚¿ãƒ–é¸æŠ
    analysis_type = st.sidebar.radio(
        "ğŸ“ˆ åˆ†æã‚¿ã‚¤ãƒ—ã‚’é¸æŠ:",
        ["ğŸ›ï¸ é€šè²¨åˆ¥åˆ†æ", "ğŸ“Š æŒ‡æ¨™åˆ¥æ¯”è¼ƒ", "ğŸ“… çµŒæ¸ˆæŒ‡æ¨™ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼", "ğŸŒ å›½åˆ¥çµŒæ¸ˆæŒ‡æ¨™ä¸€è¦§"],
        index=0
    )
    
    # ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—é¸æŠ
    value_type = st.sidebar.selectbox(
        "ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—:",
        ["forecast", "actual"],
        format_func=lambda x: "ğŸ”® äºˆæ¸¬å€¤ (Forecast)" if x == "forecast" else "ğŸ“ˆ å®Ÿéš›å€¤ (Actual)"
    )
    
    # é‡è¦åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸ¯ é‡è¦åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")
    
    # åˆ©ç”¨å¯èƒ½ãªé‡è¦åº¦ã‚’å–å¾—
    available_importance = sorted([str(i) for i in df['importance'].dropna().unique()]) if 'importance' in df.columns else []
    
    if available_importance:
        importance_mapping = {
            'high': 'ğŸ”´ é«˜ (High)',
            'medium': 'ğŸŸ¡ ä¸­ (Medium)', 
            'low': 'ğŸŸ¢ ä½ (Low)'
        }
        
        # é‡è¦åº¦ã®é¸æŠï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯highã®ã¿ï¼‰
        default_importance = ['high'] if 'high' in available_importance else (['High'] if 'High' in available_importance else available_importance)
        selected_importance = st.sidebar.multiselect(
            "è¡¨ç¤ºã™ã‚‹é‡è¦åº¦:",
            available_importance,
            default=default_importance,
            format_func=lambda x: importance_mapping.get(x, x)
        )
        
        # é‡è¦åº¦ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
        if selected_importance:
            df = df[df['importance'].isin(selected_importance)]
        else:
            st.sidebar.warning("âš ï¸ é‡è¦åº¦ã‚’å°‘ãªãã¨ã‚‚1ã¤é¸æŠã—ã¦ãã ã•ã„")
            df = df[df['importance'].isin(available_importance)]  # å…¨ã¦è¡¨ç¤º
    else:
        st.sidebar.info("ğŸ“Š é‡è¦åº¦æƒ…å ±ãŒåˆ©ç”¨ã§ãã¾ã›ã‚“")
    
    # 5é€šè²¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
    st.sidebar.markdown("---")
    st.sidebar.subheader("ğŸŒ å…¨é€šè²¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼")
    
    show_full_coverage_only = st.sidebar.checkbox(
        f"å…¨{len(all_currencies)}é€šè²¨ã§åˆ©ç”¨å¯èƒ½ãªæŒ‡æ¨™ã®ã¿è¡¨ç¤º",
        value=False,
        help=f"{len(full_coverage_indicators)}ç¨®é¡ã®æŒ‡æ¨™ãŒå…¨{len(all_currencies)}é€šè²¨ã§åˆ©ç”¨å¯èƒ½ã§ã™"
    )
    
    # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã‚’é©ç”¨
    if show_full_coverage_only:
        df = df[df['data_tag'].isin(full_coverage_indicators)]
    
    if analysis_type == "ğŸ›ï¸ é€šè²¨åˆ¥åˆ†æ":
        # é€šè²¨é¸æŠ
        currencies = sorted([str(c) for c in df['currency'].dropna().unique()])
        selected_currency = st.sidebar.selectbox(
            "ğŸ›ï¸ é€šè²¨ã‚’é¸æŠ:",
            currencies,
            index=currencies.index('USD') if 'USD' in currencies else 0
        )
        
        st.subheader(f"ğŸ›ï¸ {selected_currency} Economic Analysis")
        
        # é€šè²¨ã®è©³ç´°æƒ…å ±
        currency_data = df[df['currency'] == selected_currency]
        currency_indicators = sorted([str(tag) for tag in currency_data['data_tag'].dropna().unique() if str(tag) != "None"])
        
        col1, col2 = st.columns(2)
        with col1:
            st.info(f"ğŸ“Š **åˆ©ç”¨å¯èƒ½ãªæŒ‡æ¨™**: {len(currency_indicators)}")
        with col2:
            st.info(f"ğŸ“… **ãƒ‡ãƒ¼ã‚¿ä»¶æ•°**: {len(currency_data[currency_data['data_tag'] != 'None']):,}")
        
        # ãƒãƒ£ãƒ¼ãƒˆä½œæˆ
        charts = create_currency_chart(df, selected_currency, value_type)
        if charts:
            # å˜ä½åˆ†æçµæœã‚’è¡¨ç¤º
            if len(charts) > 1:
                st.info(f"ğŸ“ **ãƒãƒ«ãƒã‚¹ã‚±ãƒ¼ãƒ«è¡¨ç¤º**: {len(charts)}ç¨®é¡ã®ã‚¹ã‚±ãƒ¼ãƒ«ã‚°ãƒ«ãƒ¼ãƒ—ã«åˆ†ã‘ã¦è¡¨ç¤º")
            else:
                st.info(f"ğŸ“Š **çµ±ä¸€ã‚¹ã‚±ãƒ¼ãƒ«**: {charts[0]['unit_label']}")
            
            # ã‚¿ãƒ–ã¾ãŸã¯ã‚¨ã‚­ã‚¹ãƒ‘ãƒ³ãƒ€ãƒ¼ã§è¤‡æ•°ãƒãƒ£ãƒ¼ãƒˆã‚’è¡¨ç¤º
            if len(charts) > 1:
                # ã‚¿ãƒ–ã§è¡¨ç¤º
                tab_names = [f"{chart['unit_label']} ({len(chart['indicators'])}æŒ‡æ¨™)" for chart in charts]
                tabs = st.tabs(tab_names)
                
                for tab, chart_info in zip(tabs, charts):
                    with tab:
                        # å„ã‚¿ãƒ–å†…ã«æŒ‡æ¨™ãƒªã‚¹ãƒˆã‚’è¡¨ç¤º
                        with st.expander("ğŸ“Š å«ã¾ã‚Œã‚‹æŒ‡æ¨™", expanded=False):
                            indicators_text = "ã€".join(chart_info['indicators'])
                            st.write(indicators_text)
                        
                        # ãƒãƒ£ãƒ¼ãƒˆã‚’è¡¨ç¤º
                        st.plotly_chart(chart_info['figure'], use_container_width=True)
            else:
                # å˜ä¸€ãƒãƒ£ãƒ¼ãƒˆã®å ´åˆã¯ãã®ã¾ã¾è¡¨ç¤º
                st.plotly_chart(charts[0]['figure'], use_container_width=True)
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§è¡¨ç¤ºï¼‰
            st.subheader("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«")
            table_data = df[(df['currency'] == selected_currency) & (df['data_tag'] != "None")]
            if not table_data.empty:
                # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ©Ÿèƒ½
                selected_indicators = st.multiselect(
                    "è¡¨ç¤ºã™ã‚‹æŒ‡æ¨™ã‚’é¸æŠ:",
                    currency_indicators,
                    default=currency_indicators[:5]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§5ã¤è¡¨ç¤º
                )
                
                if selected_indicators:
                    filtered_table = table_data[table_data['data_tag'].isin(selected_indicators)]
                    # æœ€æ–°50ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
                    recent_data = filtered_table.sort_values('date', ascending=False).head(50)
                    
                    # é‡è¦åº¦ã‚«ãƒ©ãƒ ã‚’å«ã‚ã‚‹
                    display_columns = ['date', 'importance', 'event', 'data_tag', 'actual', 'forecast', 'previous']
                    available_columns = [col for col in display_columns if col in recent_data.columns]
                    
                    st.dataframe(
                        recent_data[available_columns],
                        use_container_width=True,
                        height=500
                    )
                    
                    # è¿½åŠ ã®ãƒ‡ãƒ¼ã‚¿è©³ç´°ã‚’å±•é–‹å¯èƒ½ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§
                    with st.expander("ğŸ” è©³ç´°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¨ãƒ‡ãƒ¼ã‚¿"):
                        # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                        col1, col2 = st.columns(2)
                        with col1:
                            start_date = st.date_input(
                                "é–‹å§‹æ—¥",
                                value=filtered_table['date'].min().date() if not filtered_table.empty else None
                            )
                        with col2:
                            end_date = st.date_input(
                                "çµ‚äº†æ—¥", 
                                value=filtered_table['date'].max().date() if not filtered_table.empty else None
                            )
                        
                        # æ—¥ä»˜ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                        if start_date and end_date:
                            date_filtered = filtered_table[
                                (filtered_table['date'].dt.date >= start_date) & 
                                (filtered_table['date'].dt.date <= end_date)
                            ]
                            
                            st.write(f"ğŸ“… æœŸé–“å†…ã®ãƒ‡ãƒ¼ã‚¿: {len(date_filtered)}ä»¶")
                            if not date_filtered.empty:
                                # é‡è¦åº¦ã‚«ãƒ©ãƒ ã‚’å«ã‚ã‚‹
                                detail_columns = ['date', 'importance', 'event', 'data_tag', 'actual', 'forecast', 'previous']
                                available_detail_columns = [col for col in detail_columns if col in date_filtered.columns]
                                
                                st.dataframe(
                                    date_filtered[available_detail_columns].sort_values('date', ascending=False),
                                    use_container_width=True,
                                    height=400
                                )
                else:
                    st.info("æŒ‡æ¨™ã‚’é¸æŠã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºã—ã¦ãã ã•ã„")
            else:
                st.warning(f"{selected_currency}ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    
    elif analysis_type == "ğŸ“Š æŒ‡æ¨™åˆ¥æ¯”è¼ƒ":  # æŒ‡æ¨™åˆ¥æ¯”è¼ƒ
        # æŒ‡æ¨™é¸æŠ
        indicators = sorted([tag for tag in df['data_tag'].unique() if tag != "None"])
        selected_indicator = st.sidebar.selectbox(
            "ğŸ“Š çµŒæ¸ˆæŒ‡æ¨™ã‚’é¸æŠ:",
            indicators,
            index=indicators.index('CPI') if 'CPI' in indicators else 0
        )
        
        st.subheader(f"ğŸ“Š {selected_indicator} Cross-Currency Comparison")
        
        # æŒ‡æ¨™ã®è©³ç´°æƒ…å ±
        indicator_data = df[df['data_tag'] == selected_indicator]
        indicator_currencies = sorted([str(c) for c in indicator_data['currency'].dropna().unique()])
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.info(f"ğŸ›ï¸ **å¯¾è±¡é€šè²¨**: {len(indicator_currencies)}")
        with col2:
            st.info(f"ğŸ“… **ãƒ‡ãƒ¼ã‚¿ä»¶æ•°**: {len(indicator_data):,}")
        with col3:
            # æŒ‡æ¨™ã®å˜ä½æƒ…å ±ã‚’è¡¨ç¤º
            if not indicator_data.empty and value_type in indicator_data.columns:
                sample_values = indicator_data[value_type].head(50)
                unit_group, unit_label = get_indicator_unit_group(selected_indicator, sample_values)
                st.info(f"ğŸ“ **å˜ä½**: {unit_label}")
        
        # ãƒãƒ£ãƒ¼ãƒˆä½œæˆ
        fig = create_indicator_chart(df, selected_indicator, value_type)
        if fig:
            st.plotly_chart(fig, use_container_width=True)
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§è¡¨ç¤ºï¼‰
            st.subheader("ğŸ“‹ ãƒ‡ãƒ¼ã‚¿ãƒ†ãƒ¼ãƒ–ãƒ«")
            table_data = df[df['data_tag'] == selected_indicator]
            if not table_data.empty:
                # é€šè²¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                selected_currencies = st.multiselect(
                    "è¡¨ç¤ºã™ã‚‹é€šè²¨ã‚’é¸æŠ:",
                    indicator_currencies,
                    default=indicator_currencies[:5]  # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã§5ã¤è¡¨ç¤º
                )
                
                if selected_currencies:
                    filtered_table = table_data[table_data['currency'].isin(selected_currencies)]
                    # æœ€æ–°50ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤º
                    recent_data = filtered_table.sort_values('date', ascending=False).head(50)
                    
                    # é‡è¦åº¦ã‚«ãƒ©ãƒ ã‚’å«ã‚ã‚‹
                    display_columns_indicator = ['date', 'currency', 'importance', 'event', 'actual', 'forecast', 'previous']
                    available_columns_indicator = [col for col in display_columns_indicator if col in recent_data.columns]
                    
                    st.dataframe(
                        recent_data[available_columns_indicator],
                        use_container_width=True,
                        height=500
                    )
                    
                    # è¿½åŠ ã®ãƒ‡ãƒ¼ã‚¿è©³ç´°ã‚’å±•é–‹å¯èƒ½ã‚»ã‚¯ã‚·ãƒ§ãƒ³ã§
                    with st.expander("ğŸ” è©³ç´°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¨ãƒ‡ãƒ¼ã‚¿"):
                        # æ—¥ä»˜ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                        col1, col2 = st.columns(2)
                        with col1:
                            start_date = st.date_input(
                                "é–‹å§‹æ—¥",
                                value=filtered_table['date'].min().date() if not filtered_table.empty else None,
                                key="indicator_start_date"
                            )
                        with col2:
                            end_date = st.date_input(
                                "çµ‚äº†æ—¥", 
                                value=filtered_table['date'].max().date() if not filtered_table.empty else None,
                                key="indicator_end_date"
                            )
                        
                        # æ—¥ä»˜ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼
                        if start_date and end_date:
                            date_filtered = filtered_table[
                                (filtered_table['date'].dt.date >= start_date) & 
                                (filtered_table['date'].dt.date <= end_date)
                            ]
                            
                            st.write(f"ğŸ“… æœŸé–“å†…ã®ãƒ‡ãƒ¼ã‚¿: {len(date_filtered)}ä»¶")
                            if not date_filtered.empty:
                                # é‡è¦åº¦ã‚«ãƒ©ãƒ ã‚’å«ã‚ã‚‹
                                detail_columns_indicator = ['date', 'currency', 'importance', 'event', 'actual', 'forecast', 'previous']
                                available_detail_indicator = [col for col in detail_columns_indicator if col in date_filtered.columns]
                                
                                st.dataframe(
                                    date_filtered[available_detail_indicator].sort_values('date', ascending=False),
                                    use_container_width=True,
                                    height=400
                                )
                else:
                    st.info("é€šè²¨ã‚’é¸æŠã—ã¦ãƒ‡ãƒ¼ã‚¿ã‚’è¡¨ç¤ºã—ã¦ãã ã•ã„")
            else:
                st.warning(f"{selected_indicator}ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    
    elif analysis_type == "ğŸ“… çµŒæ¸ˆæŒ‡æ¨™ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼":
        # çµŒæ¸ˆæŒ‡æ¨™ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼æ©Ÿèƒ½
        st.subheader("ğŸ“… çµŒæ¸ˆæŒ‡æ¨™ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼")
        
        # æ—¥ä»˜ç¯„å›²é¸æŠ
        col1, col2 = st.columns(2)
        with col1:
            start_date = st.date_input(
                "é–‹å§‹æ—¥",
                value=datetime.now() - timedelta(days=7),
                help="è¡¨ç¤ºã™ã‚‹é–‹å§‹æ—¥ã‚’é¸æŠ"
            )
        with col2:
            end_date = st.date_input(
                "çµ‚äº†æ—¥", 
                value=datetime.now() + timedelta(days=30),  # 1ãƒ¶æœˆå…ˆã¾ã§
                help="è¡¨ç¤ºã™ã‚‹çµ‚äº†æ—¥ã‚’é¸æŠ"
            )
        
        # é‡è¦åº¦ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆé€šè²¨ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ã¯å‰Šé™¤ï¼‰
        selected_importance = st.multiselect(
            "â­ é‡è¦åº¦ã‚’é¸æŠ:",
            options=['High', 'Medium', 'Low'],
            default=['High', 'Medium'],
            help="è¡¨ç¤ºã™ã‚‹é‡è¦åº¦ã‚’é¸æŠ"
        )
        
        if selected_importance and start_date <= end_date:
            # ç›´æ¥investpyã‹ã‚‰ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            try:
                with st.spinner("ğŸ“… ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—ä¸­..."):
                    from_date = start_date.strftime('%d/%m/%Y')
                    to_date = end_date.strftime('%d/%m/%Y')
                    
                    calendar_data = investpy.economic_calendar(
                        time_zone=None,
                        countries=['united states', 'euro zone', 'united kingdom', 'japan', 'australia'],
                        from_date=from_date,
                        to_date=to_date
                    )
                    
                    if not calendar_data.empty:
                        # ãƒ‡ãƒ¼ã‚¿ã®å†…å®¹ã‚’ãƒ‡ãƒãƒƒã‚°è¡¨ç¤º
                        st.info(f"ğŸ“Š å–å¾—ãƒ‡ãƒ¼ã‚¿: {len(calendar_data)}ä»¶")
                        if 'importance' in calendar_data.columns:
                            importance_counts = calendar_data['importance'].value_counts()
                            st.info(f"é‡è¦åº¦åˆ¥ä»¶æ•°: {dict(importance_counts)}")
                        
                        # é€šè²¨ãƒãƒƒãƒ”ãƒ³ã‚°
                        currency_mapping = {
                            'united states': 'USD',
                            'euro zone': 'EUR', 
                            'united kingdom': 'GBP',
                            'japan': 'JPY',
                            'australia': 'AUD'
                        }
                        
                        # zoneåˆ—ã‚’currencyã«å¤‰æ›
                        if 'zone' in calendar_data.columns:
                            calendar_data['currency_display'] = calendar_data['zone'].map(currency_mapping).fillna(calendar_data['zone'])
                        else:
                            calendar_data['currency_display'] = calendar_data.get('currency', 'Unknown')
                        
                        # é‡è¦åº¦ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆå¤§æ–‡å­—å°æ–‡å­—ã‚’çµ±ä¸€ï¼‰
                        if 'importance' in calendar_data.columns:
                            # é‡è¦åº¦ã®å€¤ã‚’æ­£è¦åŒ–
                            calendar_data['importance_normalized'] = calendar_data['importance'].str.strip().str.title()
                            selected_importance_normalized = [imp.strip().title() for imp in selected_importance]
                            calendar_filtered = calendar_data[calendar_data['importance_normalized'].isin(selected_importance_normalized)].copy()
                        else:
                            st.warning("é‡è¦åº¦åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                            calendar_filtered = calendar_data.copy()
                        
                        if not calendar_filtered.empty:
                            st.info(f"ğŸ¯ ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å¾Œ: {len(calendar_filtered)}ä»¶")
                            
                            # é‡è¦åº¦ã«ã‚ˆã‚‹è‰²åˆ†ã‘
                            importance_colors = {
                                'High': 'ğŸ”´',
                                'Medium': 'ğŸŸ¡', 
                                'Low': 'ğŸŸ¢'
                            }
                            
                            # æ—¥ä»˜å¤‰æ›
                            calendar_filtered['date_parsed'] = pd.to_datetime(calendar_filtered['date'], dayfirst=True, errors='coerce')
                            calendar_filtered = calendar_filtered.dropna(subset=['date_parsed'])
                            calendar_filtered['date_str'] = calendar_filtered['date_parsed'].dt.strftime('%Y-%m-%d')
                            
                            # æ—¥ä»˜ã”ã¨ã«ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
                            grouped = calendar_filtered.groupby('date_str')
                            
                            for date_str, group in grouped:
                                with st.expander(f"ğŸ“… {date_str} ({len(group)}ä»¶)", expanded=True):
                                    # é‡è¦åº¦é †ã«ã‚½ãƒ¼ãƒˆ
                                    importance_order = {'High': 0, 'Medium': 1, 'Low': 2}
                                    group['importance_rank'] = group['importance'].map(importance_order).fillna(3)
                                    group_sorted = group.sort_values(['importance_rank', 'time'])
                                    
                                    for _, row in group_sorted.iterrows():
                                        # æ­£è¦åŒ–ã•ã‚ŒãŸé‡è¦åº¦ã‚’ä½¿ç”¨
                                        importance_display = row.get('importance_normalized', row.get('importance', ''))
                                        importance_icon = importance_colors.get(importance_display, 'âšª')
                                        
                                        # æ™‚é–“æƒ…å ±ã‚’å–å¾—
                                        time_info = row.get('time', '')
                                        if pd.notna(time_info) and str(time_info) != '':
                                            time_display = f"â° {time_info}"
                                        else:
                                            time_display = ""
                                        
                                        col1, col2, col3, col4, col5 = st.columns([1, 1, 1, 4, 2])
                                        with col1:
                                            st.write(f"{importance_icon}")
                                        with col2:
                                            st.write(f"**{row['currency_display']}**")
                                        with col3:
                                            st.write(time_display)
                                        with col4:
                                            st.write(f"{row['event']}")
                                        with col5:
                                            if pd.notna(row.get('actual')) and str(row.get('actual')) != '':
                                                st.write(f"å®Ÿç¸¾: **{row['actual']}**")
                                            elif pd.notna(row.get('forecast')) and str(row.get('forecast')) != '':
                                                st.write(f"äºˆæ¸¬: {row['forecast']}")
                                            else:
                                                st.write("--")
                        else:
                            st.info("é¸æŠã•ã‚ŒãŸé‡è¦åº¦ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                    else:
                        st.warning("æŒ‡å®šæœŸé–“ã«ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                        
            except Exception as e:
                st.error(f"ã‚«ãƒ¬ãƒ³ãƒ€ãƒ¼ãƒ‡ãƒ¼ã‚¿å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        else:
            st.warning("é‡è¦åº¦ã‚’é¸æŠã—ã€æ­£ã—ã„æ—¥ä»˜ç¯„å›²ã‚’è¨­å®šã—ã¦ãã ã•ã„")
    
    elif analysis_type == "ğŸŒ å›½åˆ¥çµŒæ¸ˆæŒ‡æ¨™ä¸€è¦§":
        # å›½åˆ¥çµŒæ¸ˆæŒ‡æ¨™ãƒ’ã‚¹ãƒˆãƒªã‚«ãƒ«ä¸€è¦§
        st.subheader("ğŸŒ å›½åˆ¥çµŒæ¸ˆæŒ‡æ¨™ãƒ’ã‚¹ãƒˆãƒªã‚«ãƒ«ä¸€è¦§")
        
        # å›½é¸æŠ
        country_mapping = {
            'USD': 'ğŸ‡ºğŸ‡¸ ã‚¢ãƒ¡ãƒªã‚«',
            'EUR': 'ğŸ‡ªğŸ‡º ãƒ¦ãƒ¼ãƒ­åœ', 
            'GBP': 'ğŸ‡¬ğŸ‡§ ã‚¤ã‚®ãƒªã‚¹',
            'JPY': 'ğŸ‡¯ğŸ‡µ æ—¥æœ¬',
            'AUD': 'ğŸ‡¦ğŸ‡º ã‚ªãƒ¼ã‚¹ãƒˆãƒ©ãƒªã‚¢'
        }
        
        available_currencies = sorted([str(c) for c in df['currency'].dropna().unique()])
        selected_country = st.selectbox(
            "ğŸ›ï¸ å›½ã‚’é¸æŠ:",
            options=available_currencies,
            format_func=lambda x: country_mapping.get(x, x),
            help="è¡¨ç¤ºã™ã‚‹å›½ã‚’é¸æŠã—ã¦ãã ã•ã„"
        )
        
        if selected_country:
            # é¸æŠã•ã‚ŒãŸå›½ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
            country_data = df[df['currency'] == selected_country].copy()
            
            if not country_data.empty:
                # ç›´è¿‘2å¹´åˆ†ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                country_data['year'] = pd.to_datetime(country_data['date']).dt.year
                available_years = sorted(country_data['year'].dropna().unique(), reverse=True)
                
                # ç›´è¿‘2å¹´ã‚’è‡ªå‹•é¸æŠ
                recent_years = available_years[:2] if len(available_years) >= 2 else available_years
                
                col1, col2 = st.columns(2)
                with col1:
                    # ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—é¸æŠï¼ˆactualã¾ãŸã¯forecastï¼‰
                    data_type = st.selectbox(
                        "ğŸ“Š ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—:",
                        options=['actual', 'forecast'],
                        format_func=lambda x: "ğŸ“ˆ å®Ÿç¸¾å€¤" if x == "actual" else "ğŸ”® äºˆæ¸¬å€¤"
                    )
                with col2:
                    st.info(f"ğŸ“… è¡¨ç¤ºæœŸé–“: {min(recent_years)}å¹´ - {max(recent_years)}å¹´")
                
                # ç›´è¿‘2å¹´ã®ãƒ‡ãƒ¼ã‚¿ã‚’å–å¾—
                year_data = country_data[country_data['year'].isin(recent_years)].copy()
                
                if not year_data.empty:
                    # å¹´æœˆã¨ã‚¤ãƒ™ãƒ³ãƒˆã§ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
                    year_data['year_month'] = pd.to_datetime(year_data['date']).dt.strftime('%Yå¹´%mæœˆ')
                    
                    # çµŒæ¸ˆæŒ‡æ¨™ã®æ—¥æœ¬èªå¤‰æ›ãƒãƒƒãƒ”ãƒ³ã‚°
                    indicator_japanese = {
                        'Unemployment Rate': 'å¤±æ¥­ç‡',
                        'Employment Rate': 'é›‡ç”¨ç‡', 
                        'Initial Jobless Claims': 'æ–°è¦å¤±æ¥­ä¿é™ºç”³è«‹ä»¶æ•°',
                        'Continuing Jobless Claims': 'ç¶™ç¶šå¤±æ¥­ä¿é™ºç”³è«‹ä»¶æ•°',
                        'CPI (YoY)': 'æ¶ˆè²»è€…ç‰©ä¾¡æŒ‡æ•°(å‰å¹´æ¯”)',
                        'CPI (MoM)': 'æ¶ˆè²»è€…ç‰©ä¾¡æŒ‡æ•°(å‰æœˆæ¯”)',
                        'Core CPI (YoY)': 'ã‚³ã‚¢æ¶ˆè²»è€…ç‰©ä¾¡æŒ‡æ•°(å‰å¹´æ¯”)',
                        'Core CPI (MoM)': 'ã‚³ã‚¢æ¶ˆè²»è€…ç‰©ä¾¡æŒ‡æ•°(å‰æœˆæ¯”)',
                        'National CPI (YoY)': 'å…¨å›½æ¶ˆè²»è€…ç‰©ä¾¡æŒ‡æ•°(å‰å¹´æ¯”)',
                        'National CPI (MoM)': 'å…¨å›½æ¶ˆè²»è€…ç‰©ä¾¡æŒ‡æ•°(å‰æœˆæ¯”)',
                        'Tokyo CPI (YoY)': 'æ±äº¬æ¶ˆè²»è€…ç‰©ä¾¡æŒ‡æ•°(å‰å¹´æ¯”)',
                        'Tokyo CPI (MoM)': 'æ±äº¬æ¶ˆè²»è€…ç‰©ä¾¡æŒ‡æ•°(å‰æœˆæ¯”)',
                        'PPI (YoY)': 'ç”Ÿç”£è€…ç‰©ä¾¡æŒ‡æ•°(å‰å¹´æ¯”)',
                        'PPI (MoM)': 'ç”Ÿç”£è€…ç‰©ä¾¡æŒ‡æ•°(å‰æœˆæ¯”)',
                        'GDP (QoQ)': 'GDP(å‰æœŸæ¯”)',
                        'GDP (YoY)': 'GDP(å‰å¹´æ¯”)',
                        'Current Account': 'çµŒå¸¸åæ”¯',
                        'Trade Balance': 'è²¿æ˜“åæ”¯',
                        'PMI Manufacturing': 'è£½é€ æ¥­PMI',
                        'PMI Services': 'ã‚µãƒ¼ãƒ“ã‚¹æ¥­PMI',
                        'Industrial Production (YoY)': 'é‰±å·¥æ¥­ç”Ÿç”£æŒ‡æ•°(å‰å¹´æ¯”)',
                        'Industrial Production (MoM)': 'é‰±å·¥æ¥­ç”Ÿç”£æŒ‡æ•°(å‰æœˆæ¯”)',
                        'Factory Orders': 'å·¥å ´å—æ³¨',
                        'Building Permits': 'å»ºè¨­è¨±å¯ä»¶æ•°',
                        'Housing Starts': 'ä½å®…ç€å·¥ä»¶æ•°',
                        'Interest Rate': 'æ”¿ç­–é‡‘åˆ©',
                        'Retail Sales (YoY)': 'å°å£²å£²ä¸Šé«˜(å‰å¹´æ¯”)',
                        'Retail Sales (MoM)': 'å°å£²å£²ä¸Šé«˜(å‰æœˆæ¯”)',
                        'Housing Prices (YoY)': 'ä½å®…ä¾¡æ ¼æŒ‡æ•°(å‰å¹´æ¯”)',
                        'Housing Prices (MoM)': 'ä½å®…ä¾¡æ ¼æŒ‡æ•°(å‰æœˆæ¯”)',
                        'Consumer Confidence': 'æ¶ˆè²»è€…ä¿¡é ¼æ„ŸæŒ‡æ•°'
                    }
                    
                    # çµŒæ¸ˆæŒ‡æ¨™ã‚’ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«åˆ†é¡
                    indicator_categories = {
                        'ğŸ‘¥ é›‡ç”¨é–¢é€£': ['Unemployment Rate', 'Employment Rate', 'Initial Jobless Claims', 'Continuing Jobless Claims'],
                        'ğŸ’° ç‰©ä¾¡é–¢é€£': ['CPI (YoY)', 'CPI (MoM)', 'Core CPI (YoY)', 'Core CPI (MoM)', 'National CPI (YoY)', 'National CPI (MoM)', 'Tokyo CPI (YoY)', 'Tokyo CPI (MoM)', 'PPI (YoY)', 'PPI (MoM)'],
                        'ğŸ“ˆ æ™¯æ°—é–¢é€£': ['GDP (QoQ)', 'GDP (YoY)', 'Current Account', 'Trade Balance', 'PMI Manufacturing', 'PMI Services'],
                        'ğŸ­ è£½é€ æ¥­é–¢é€£': ['Industrial Production (YoY)', 'Industrial Production (MoM)', 'Factory Orders', 'Building Permits', 'Housing Starts'],
                        'ğŸ¦ æ”¿ç­–é‡‘åˆ©': ['Interest Rate'],
                        'ğŸ›’ æ¶ˆè²»é–¢é€£': ['Retail Sales (YoY)', 'Retail Sales (MoM)', 'Housing Prices (YoY)', 'Housing Prices (MoM)', 'Consumer Confidence']
                    }
                    
                    # å…¨æŒ‡æ¨™ãƒªã‚¹ãƒˆ
                    all_major_indicators = []
                    for indicators in indicator_categories.values():
                        all_major_indicators.extend(indicators)
                    
                    # ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚°ãŒä¸»è¦æŒ‡æ¨™ã«å«ã¾ã‚Œã‚‹ãƒ‡ãƒ¼ã‚¿ã‚’æŠ½å‡º
                    filtered_data = year_data[year_data['data_tag'].isin(all_major_indicators)].copy()
                    
                    if not filtered_data.empty:
                        # ãƒ”ãƒœãƒƒãƒˆãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
                        try:
                            pivot_table = filtered_data.pivot_table(
                                index='year_month',
                                columns='data_tag',
                                values=data_type,
                                aggfunc='last'  # æœ€æ–°ã®å€¤ã‚’ä½¿ç”¨
                            )
                            
                            # å¹´æœˆé †ã«ä¸¦ã³æ›¿ãˆ
                            all_periods = sorted(pivot_table.index)
                            
                            # ãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹æŒ‡æ¨™ã®ã¿è¡¨ç¤º
                            available_indicators = [col for col in pivot_table.columns if not pivot_table[col].isna().all()]
                            
                            if available_indicators:
                                st.subheader(f"{country_mapping.get(selected_country, selected_country)} - ç›´è¿‘2å¹´é–“ çµŒæ¸ˆæŒ‡æ¨™ä¸€è¦§")
                                
                                # çµ±è¨ˆæƒ…å ±è¡¨ç¤º
                                col1, col2, col3 = st.columns(3)
                                with col1:
                                    st.metric("ğŸ“Š æŒ‡æ¨™æ•°", len(available_indicators))
                                with col2:
                                    st.metric("ğŸ“… ãƒ‡ãƒ¼ã‚¿æœŸé–“", f"{min(recent_years)}-{max(recent_years)}å¹´")
                                with col3:
                                    total_data_points = pivot_table[available_indicators].notna().sum().sum()
                                    st.metric("ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ³ãƒˆ", total_data_points)
                                
                                # ç¸¦è»¸ã«ã‚«ãƒ†ã‚´ãƒªãƒ»æŒ‡æ¨™ã€æ¨ªè»¸ã«æœˆã®ãƒ†ãƒ¼ãƒ–ãƒ«ä½œæˆ
                                structured_data = []
                                
                                for category_name, indicators in indicator_categories.items():
                                    # ãã®ã‚«ãƒ†ã‚´ãƒªã®æŒ‡æ¨™ã§åˆ©ç”¨å¯èƒ½ãªã‚‚ã®
                                    category_indicators = [ind for ind in indicators if ind in available_indicators]
                                    
                                    if category_indicators:
                                        # ã‚«ãƒ†ã‚´ãƒªãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã‚’è¿½åŠ 
                                        category_row = {'ã‚¸ãƒ£ãƒ³ãƒ«': category_name, 'æŒ‡æ¨™å': ''}
                                        for month in pivot_table.index:
                                            category_row[month] = ''
                                        structured_data.append(category_row)
                                        
                                        # å„æŒ‡æ¨™ã®è¡Œã‚’è¿½åŠ 
                                        for indicator in category_indicators:
                                            # æ—¥æœ¬èªåã‚’å–å¾—ã€ãªã‘ã‚Œã°è‹±èªåã‚’ãã®ã¾ã¾ä½¿ç”¨
                                            japanese_name = indicator_japanese.get(indicator, indicator)
                                            indicator_row = {'ã‚¸ãƒ£ãƒ³ãƒ«': '', 'æŒ‡æ¨™å': japanese_name}
                                            for month in pivot_table.index:
                                                value = pivot_table.loc[month, indicator] if month in pivot_table.index else None
                                                if pd.notna(value) and isinstance(value, (int, float)):
                                                    indicator_row[month] = f"{value:.2f}"
                                                else:
                                                    indicator_row[month] = "--"
                                            structured_data.append(indicator_row)
                                
                                # DataFrameã«å¤‰æ›
                                if structured_data:
                                    structured_df = pd.DataFrame(structured_data)
                                    
                                    # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’è¨­å®š
                                    structured_df = structured_df.set_index(['ã‚¸ãƒ£ãƒ³ãƒ«', 'æŒ‡æ¨™å'])
                                    
                                    # æ•°å€¤ãƒ‡ãƒ¼ã‚¿ã®å¤‰åŒ–ã«åŸºã¥ã„ã¦ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°é–¢æ•°ã‚’å®šç¾©
                                    def color_changes(val):
                                        if val == "--" or val == "":
                                            return 'background-color: #f0f0f0'  # ã‚°ãƒ¬ãƒ¼ï¼ˆãƒ‡ãƒ¼ã‚¿ãªã—ï¼‰
                                        return ''
                                    
                                    def highlight_dataframe(df):
                                        # å„è¡Œï¼ˆæŒ‡æ¨™ï¼‰ã«ã¤ã„ã¦å‰æœˆæ¯”ã§ã®è‰²åˆ†ã‘
                                        styled_df = df.copy()
                                        
                                        for idx in df.index:
                                            if df.loc[idx].name[1] != '':  # æŒ‡æ¨™åãŒç©ºã§ãªã„è¡Œã®ã¿å‡¦ç†
                                                row_values = []
                                                for col in df.columns:
                                                    val = df.loc[idx, col]
                                                    if val != "--" and val != "":
                                                        try:
                                                            row_values.append((col, float(val)))
                                                        except:
                                                            row_values.append((col, None))
                                                    else:
                                                        row_values.append((col, None))
                                                
                                                # å‰æœˆæ¯”ã§ã®è‰²åˆ†ã‘
                                                for i, (col, current_val) in enumerate(row_values):
                                                    if current_val is not None and i > 0:
                                                        prev_val = row_values[i-1][1]
                                                        if prev_val is not None:
                                                            if current_val > prev_val:
                                                                styled_df.loc[idx, col] = f'<span style="background-color: rgba(255, 200, 200, 0.5)">{df.loc[idx, col]}</span>'
                                                            elif current_val < prev_val:
                                                                styled_df.loc[idx, col] = f'<span style="background-color: rgba(200, 255, 200, 0.5)">{df.loc[idx, col]}</span>'
                                                            else:
                                                                styled_df.loc[idx, col] = f'<span style="background-color: rgba(240, 240, 240, 0.5)">{df.loc[idx, col]}</span>'
                                        
                                        return styled_df
                                    
                                    # ã‚¹ã‚¿ã‚¤ãƒ«é©ç”¨
                                    try:
                                        def style_row(row):
                                            styles = []
                                            for i in range(len(row)):
                                                if row.iloc[i] == '--' or row.iloc[i] == '':
                                                    styles.append('background-color: rgba(240, 240, 240, 0.3)')
                                                else:
                                                    try:
                                                        current_val = float(row.iloc[i])
                                                        
                                                        # å‰ã®æœ‰åŠ¹ãªå€¤ã‚’é¡ã£ã¦æ¤œç´¢
                                                        prev_val = None
                                                        for j in range(i-1, -1, -1):
                                                            if row.iloc[j] != '--' and row.iloc[j] != '':
                                                                try:
                                                                    prev_val = float(row.iloc[j])
                                                                    break
                                                                except:
                                                                    continue
                                                        
                                                        if prev_val is not None:
                                                            if current_val > prev_val:
                                                                styles.append('background-color: rgba(255, 200, 200, 0.3)')
                                                            elif current_val < prev_val:
                                                                styles.append('background-color: rgba(200, 255, 200, 0.3)')
                                                            else:
                                                                styles.append('background-color: rgba(255, 255, 200, 0.3)')
                                                        else:
                                                            styles.append('')  # æ¯”è¼ƒå¯¾è±¡ãŒãªã„å ´åˆ
                                                    except:
                                                        styles.append('')
                                            return styles
                                        
                                        styled_df = structured_df.style.apply(style_row, axis=1)
                                        
                                        st.dataframe(
                                            styled_df,
                                            use_container_width=True,
                                            height=min(600, len(structured_df) * 35 + 100)
                                        )
                                    except:
                                        # ã‚¹ã‚¿ã‚¤ãƒªãƒ³ã‚°ã«å¤±æ•—ã—ãŸå ´åˆã¯é€šå¸¸ã®DataFrameã‚’è¡¨ç¤º
                                        st.dataframe(
                                            structured_df,
                                            use_container_width=True,
                                            height=min(600, len(structured_df) * 35 + 100)
                                        )
                                    
                                    # å‡¡ä¾‹ã‚’è¿½åŠ 
                                    st.markdown("""
                                    **ğŸ“Š è‰²åˆ†ã‘å‡¡ä¾‹:**
                                    - ğŸ”´ **è–„ã„èµ¤**: å‰æœˆã‚ˆã‚Šå¢—åŠ 
                                    - ğŸŸ¢ **è–„ã„ç·‘**: å‰æœˆã‚ˆã‚Šæ¸›å°‘  
                                    - âš« **ã‚°ãƒ¬ãƒ¼**: ãƒ‡ãƒ¼ã‚¿ãªã—
                                    """)
                                
                                # æ³¨æ„æ›¸ã
                                st.info("""
                                ğŸ“Œ **æ³¨æ„äº‹é …**
                                - ãƒ‡ãƒ¼ã‚¿ã¯ investpy ã‹ã‚‰å–å¾—ã—ãŸå®Ÿéš›ã®çµŒæ¸ˆæŒ‡æ¨™ã§ã™
                                - "--" ã¯è©²å½“æœˆã«ãƒ‡ãƒ¼ã‚¿ãŒç™ºè¡¨ã•ã‚Œã¦ã„ãªã„ã“ã¨ã‚’ç¤ºã—ã¾ã™
                                - æ•°å€¤ã®å˜ä½ã¯æŒ‡æ¨™ã«ã‚ˆã‚Šç•°ãªã‚Šã¾ã™ï¼ˆ%ã€æ•°å€¤ãªã©ï¼‰
                                - å°†æ¥ã®æŠ•è³‡åˆ¤æ–­ã®å‚è€ƒã¨ã—ã¦ã”åˆ©ç”¨ãã ã•ã„
                                """)
                                
                            else:
                                st.warning(f"{selected_year}å¹´ã®ä¸»è¦çµŒæ¸ˆæŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                        except Exception as e:
                            st.error(f"ãƒ‡ãƒ¼ã‚¿å‡¦ç†ã‚¨ãƒ©ãƒ¼: {e}")
                    else:
                        st.warning(f"{selected_year}å¹´ã®ä¸»è¦çµŒæ¸ˆæŒ‡æ¨™ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
                else:
                    st.warning(f"{selected_year}å¹´ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
            else:
                st.warning(f"{country_mapping.get(selected_country, selected_country)}ã®ãƒ‡ãƒ¼ã‚¿ãŒã‚ã‚Šã¾ã›ã‚“")
    
    # ãƒ•ãƒƒã‚¿ãƒ¼
    st.markdown("---")
    st.markdown(
        f"""
        <div style='text-align: center; color: #666;'>
        ğŸ“Š Economic Dashboard | Built with Streamlit<br>
        ğŸ”„ Last Updated: {time.strftime('%Y-%m-%d %H:%M:%S')} | 
        ğŸ’¾ Data Cache: 30 minutes | 
        ğŸŸ¢ Status: Connected
        </div>
        """,
        unsafe_allow_html=True
    )

if __name__ == "__main__":
    main()